{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":81933,"databundleVersionId":9643020,"sourceType":"competition"},{"sourceId":10144188,"sourceType":"datasetVersion","datasetId":6261488},{"sourceId":10161833,"sourceType":"datasetVersion","datasetId":6274967},{"sourceId":10200802,"sourceType":"datasetVersion","datasetId":6303553},{"sourceId":10203245,"sourceType":"datasetVersion","datasetId":6305398},{"sourceId":10208164,"sourceType":"datasetVersion","datasetId":6308872},{"sourceId":198747,"sourceType":"modelInstanceVersion","modelInstanceId":169524,"modelId":191870}],"dockerImageVersionId":30805,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import polars as pl\nimport numpy as np\nimport pandas as pd\nimport os\nfrom concurrent.futures import ThreadPoolExecutor\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nimport torch.optim as optim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:24:38.456516Z","iopub.execute_input":"2024-12-23T09:24:38.456887Z","iopub.status.idle":"2024-12-23T09:24:38.462095Z","shell.execute_reply.started":"2024-12-23T09:24:38.456853Z","shell.execute_reply":"2024-12-23T09:24:38.461187Z"}},"outputs":[],"execution_count":199},{"cell_type":"markdown","source":"## PARQUET PROCESSING","metadata":{}},{"cell_type":"code","source":"def process_file(filename, dirname):\n    \"\"\"\n    return describe value and people's id.\n    \"\"\"\n    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n    df.drop('step', axis=1, inplace=True)\n    return df.describe().values.reshape(-1), filename.split('=')[1]\n\ndef load_time_series(dirname) -> pd.DataFrame:\n    \"\"\"\n    ids: chuỗi các file trong parquet\n    results: kết quả áp dụng process_file cho từng file trong paquet\n    \n    \"\"\"\n    ids = os.listdir(dirname)\n    with ThreadPoolExecutor() as executor:\n        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n    # chia kết quả từ results thành 2 phần\n    stats, indexes = zip(*results)\n    # tạo bảng từ các số liệu thống kê, mỗi hàng một người dùng \n    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n    df['id'] = indexes\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:24:38.463679Z","iopub.execute_input":"2024-12-23T09:24:38.464590Z","iopub.status.idle":"2024-12-23T09:24:38.475381Z","shell.execute_reply.started":"2024-12-23T09:24:38.464550Z","shell.execute_reply":"2024-12-23T09:24:38.474474Z"}},"outputs":[],"execution_count":200},{"cell_type":"code","source":"train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\ntest_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:24:38.476886Z","iopub.execute_input":"2024-12-23T09:24:38.477226Z","iopub.status.idle":"2024-12-23T09:25:46.942251Z","shell.execute_reply.started":"2024-12-23T09:24:38.477190Z","shell.execute_reply":"2024-12-23T09:25:46.941221Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 996/996 [01:08<00:00, 14.59it/s]\n100%|██████████| 2/2 [00:00<00:00, 13.82it/s]\n","output_type":"stream"}],"execution_count":201},{"cell_type":"markdown","source":"#### fill parquet with autoencoder","metadata":{}},{"cell_type":"code","source":"class AutoEncoder(nn.Module):\n    def __init__(self, input_dim, encoding_dim):\n        super(AutoEncoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, encoding_dim*3),\n            nn.GELU(),\n            nn.Linear(encoding_dim*3, encoding_dim*2),\n            nn.GELU(),\n            nn.Linear(encoding_dim*2, encoding_dim),\n            nn.GELU()\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(encoding_dim, input_dim*2),\n            nn.GELU(),\n            nn.Linear(input_dim*2, input_dim*3),\n            nn.GELU(),\n            nn.Linear(input_dim*3, input_dim),\n            nn.Sigmoid()\n        )\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:25:46.943638Z","iopub.execute_input":"2024-12-23T09:25:46.943880Z","iopub.status.idle":"2024-12-23T09:25:46.950042Z","shell.execute_reply.started":"2024-12-23T09:25:46.943856Z","shell.execute_reply":"2024-12-23T09:25:46.949224Z"}},"outputs":[],"execution_count":202},{"cell_type":"code","source":"def perform_autoencoder(df, encoding_dim=50, epochs=50, batch_size=32):\n    scaler = StandardScaler()\n    df_scaled = scaler.fit_transform(df)\n    \n    data_tensor = torch.FloatTensor(df_scaled)\n    \n    input_dim = data_tensor.shape[1]\n    autoencoder = AutoEncoder(input_dim, encoding_dim)\n    \n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(autoencoder.parameters())\n    \n    for epoch in range(epochs):\n        for i in range(0, len(data_tensor), batch_size):\n            batch = data_tensor[i : i + batch_size]\n            optimizer.zero_grad()\n            reconstructed = autoencoder(batch)\n            loss = criterion(reconstructed, batch)\n            loss.backward()\n            optimizer.step()\n        if (epoch + 1) % 10 == 0:\n            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}]')\n                 \n    with torch.no_grad():\n        encoded_data = autoencoder.encoder(data_tensor).numpy()\n        \n    df_encoded = pd.DataFrame(encoded_data, columns=[f'Enc_{i + 1}' for i in range(encoded_data.shape[1])])\n    \n    return df_encoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:25:46.951156Z","iopub.execute_input":"2024-12-23T09:25:46.951408Z","iopub.status.idle":"2024-12-23T09:25:46.963326Z","shell.execute_reply.started":"2024-12-23T09:25:46.951383Z","shell.execute_reply":"2024-12-23T09:25:46.962458Z"}},"outputs":[],"execution_count":203},{"cell_type":"code","source":"df_train = train_ts.drop('id', axis=1)\ndf_test = test_ts.drop('id', axis=1)\ndf_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:25:46.964822Z","iopub.execute_input":"2024-12-23T09:25:46.965103Z","iopub.status.idle":"2024-12-23T09:25:47.003195Z","shell.execute_reply.started":"2024-12-23T09:25:46.965063Z","shell.execute_reply":"2024-12-23T09:25:47.002354Z"}},"outputs":[{"execution_count":204,"output_type":"execute_result","data":{"text/plain":"       stat_0    stat_1    stat_2    stat_3    stat_4    stat_5    stat_6  \\\n0     50458.0   50458.0   50458.0   50458.0   50458.0   50458.0   50458.0   \n1    340584.0  340584.0  340584.0  340584.0  340584.0  340584.0  340584.0   \n2     40003.0   40003.0   40003.0   40003.0   40003.0   40003.0   40003.0   \n3    223915.0  223915.0  223915.0  223915.0  223915.0  223915.0  223915.0   \n4     15420.0   15420.0   15420.0   15420.0   15420.0   15420.0   15420.0   \n..        ...       ...       ...       ...       ...       ...       ...   \n991  394128.0  394128.0  394128.0  394128.0  394128.0  394128.0  394128.0   \n992    1195.0    1195.0    1195.0    1195.0    1195.0    1195.0    1195.0   \n993  393240.0  393240.0  393240.0  393240.0  393240.0  393240.0  393240.0   \n994   40085.0   40085.0   40085.0   40085.0   40085.0   40085.0   40085.0   \n995  342324.0  342324.0  342324.0  342324.0  342324.0  342324.0  342324.0   \n\n       stat_7    stat_8    stat_9  ...   stat_86   stat_87    stat_88  \\\n0     50458.0   50458.0   50458.0  ...  1.738203  5.314874  89.422226   \n1    340584.0  340584.0  340584.0  ...  2.475326  3.966906  89.080330   \n2     40003.0   40003.0   40003.0  ...  1.746797  5.066334  86.987267   \n3    223915.0  223915.0  223915.0  ...  1.269051  6.134459  89.976074   \n4     15420.0   15420.0   15420.0  ...  1.071875  2.774382  89.300034   \n..        ...       ...       ...  ...       ...       ...        ...   \n991  394128.0  394128.0  394128.0  ...  2.099614  3.669502  89.025551   \n992    1195.0    1195.0    1195.0  ...  0.996484  1.786410  81.665283   \n993  393240.0  393240.0  393240.0  ...  1.547813  3.692727  89.333710   \n994   40085.0   40085.0   40085.0  ...  0.999219  1.673958  88.629547   \n995  342324.0  342324.0  342324.0  ...  1.006835  1.009104  88.652969   \n\n     stat_89      stat_90  stat_91       stat_92  stat_93  stat_94  stat_95  \n0        0.0  2626.199951   4187.0  8.639500e+13      7.0      2.0     57.0  \n1        1.0  2628.199951   4146.0  8.639500e+13      7.0      2.0    243.0  \n2        0.0  2618.199951   4183.0  8.636500e+13      7.0      3.0    134.0  \n3        0.0  2502.000000   6000.0  8.639500e+13      7.0      4.0     72.0  \n4        0.0  1046.800049   4199.0  8.601500e+13      7.0      4.0     76.0  \n..       ...          ...      ...           ...      ...      ...      ...  \n991      1.0  2576.399902   4191.0  8.639500e+13      7.0      4.0    161.0  \n992      0.0  1526.599976   4194.0  8.514000e+13      7.0      2.0    130.0  \n993      1.0  2592.199951   4178.0  8.639500e+13      7.0      1.0     79.0  \n994      0.0  1875.199951   4183.0  8.639500e+13      7.0      1.0    155.0  \n995      1.0  1196.599976   4176.0  8.639500e+13      7.0      4.0     20.0  \n\n[996 rows x 96 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stat_0</th>\n      <th>stat_1</th>\n      <th>stat_2</th>\n      <th>stat_3</th>\n      <th>stat_4</th>\n      <th>stat_5</th>\n      <th>stat_6</th>\n      <th>stat_7</th>\n      <th>stat_8</th>\n      <th>stat_9</th>\n      <th>...</th>\n      <th>stat_86</th>\n      <th>stat_87</th>\n      <th>stat_88</th>\n      <th>stat_89</th>\n      <th>stat_90</th>\n      <th>stat_91</th>\n      <th>stat_92</th>\n      <th>stat_93</th>\n      <th>stat_94</th>\n      <th>stat_95</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50458.0</td>\n      <td>50458.0</td>\n      <td>50458.0</td>\n      <td>50458.0</td>\n      <td>50458.0</td>\n      <td>50458.0</td>\n      <td>50458.0</td>\n      <td>50458.0</td>\n      <td>50458.0</td>\n      <td>50458.0</td>\n      <td>...</td>\n      <td>1.738203</td>\n      <td>5.314874</td>\n      <td>89.422226</td>\n      <td>0.0</td>\n      <td>2626.199951</td>\n      <td>4187.0</td>\n      <td>8.639500e+13</td>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>57.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>340584.0</td>\n      <td>340584.0</td>\n      <td>340584.0</td>\n      <td>340584.0</td>\n      <td>340584.0</td>\n      <td>340584.0</td>\n      <td>340584.0</td>\n      <td>340584.0</td>\n      <td>340584.0</td>\n      <td>340584.0</td>\n      <td>...</td>\n      <td>2.475326</td>\n      <td>3.966906</td>\n      <td>89.080330</td>\n      <td>1.0</td>\n      <td>2628.199951</td>\n      <td>4146.0</td>\n      <td>8.639500e+13</td>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>243.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>40003.0</td>\n      <td>40003.0</td>\n      <td>40003.0</td>\n      <td>40003.0</td>\n      <td>40003.0</td>\n      <td>40003.0</td>\n      <td>40003.0</td>\n      <td>40003.0</td>\n      <td>40003.0</td>\n      <td>40003.0</td>\n      <td>...</td>\n      <td>1.746797</td>\n      <td>5.066334</td>\n      <td>86.987267</td>\n      <td>0.0</td>\n      <td>2618.199951</td>\n      <td>4183.0</td>\n      <td>8.636500e+13</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>134.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>223915.0</td>\n      <td>223915.0</td>\n      <td>223915.0</td>\n      <td>223915.0</td>\n      <td>223915.0</td>\n      <td>223915.0</td>\n      <td>223915.0</td>\n      <td>223915.0</td>\n      <td>223915.0</td>\n      <td>223915.0</td>\n      <td>...</td>\n      <td>1.269051</td>\n      <td>6.134459</td>\n      <td>89.976074</td>\n      <td>0.0</td>\n      <td>2502.000000</td>\n      <td>6000.0</td>\n      <td>8.639500e+13</td>\n      <td>7.0</td>\n      <td>4.0</td>\n      <td>72.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15420.0</td>\n      <td>15420.0</td>\n      <td>15420.0</td>\n      <td>15420.0</td>\n      <td>15420.0</td>\n      <td>15420.0</td>\n      <td>15420.0</td>\n      <td>15420.0</td>\n      <td>15420.0</td>\n      <td>15420.0</td>\n      <td>...</td>\n      <td>1.071875</td>\n      <td>2.774382</td>\n      <td>89.300034</td>\n      <td>0.0</td>\n      <td>1046.800049</td>\n      <td>4199.0</td>\n      <td>8.601500e+13</td>\n      <td>7.0</td>\n      <td>4.0</td>\n      <td>76.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>991</th>\n      <td>394128.0</td>\n      <td>394128.0</td>\n      <td>394128.0</td>\n      <td>394128.0</td>\n      <td>394128.0</td>\n      <td>394128.0</td>\n      <td>394128.0</td>\n      <td>394128.0</td>\n      <td>394128.0</td>\n      <td>394128.0</td>\n      <td>...</td>\n      <td>2.099614</td>\n      <td>3.669502</td>\n      <td>89.025551</td>\n      <td>1.0</td>\n      <td>2576.399902</td>\n      <td>4191.0</td>\n      <td>8.639500e+13</td>\n      <td>7.0</td>\n      <td>4.0</td>\n      <td>161.0</td>\n    </tr>\n    <tr>\n      <th>992</th>\n      <td>1195.0</td>\n      <td>1195.0</td>\n      <td>1195.0</td>\n      <td>1195.0</td>\n      <td>1195.0</td>\n      <td>1195.0</td>\n      <td>1195.0</td>\n      <td>1195.0</td>\n      <td>1195.0</td>\n      <td>1195.0</td>\n      <td>...</td>\n      <td>0.996484</td>\n      <td>1.786410</td>\n      <td>81.665283</td>\n      <td>0.0</td>\n      <td>1526.599976</td>\n      <td>4194.0</td>\n      <td>8.514000e+13</td>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>130.0</td>\n    </tr>\n    <tr>\n      <th>993</th>\n      <td>393240.0</td>\n      <td>393240.0</td>\n      <td>393240.0</td>\n      <td>393240.0</td>\n      <td>393240.0</td>\n      <td>393240.0</td>\n      <td>393240.0</td>\n      <td>393240.0</td>\n      <td>393240.0</td>\n      <td>393240.0</td>\n      <td>...</td>\n      <td>1.547813</td>\n      <td>3.692727</td>\n      <td>89.333710</td>\n      <td>1.0</td>\n      <td>2592.199951</td>\n      <td>4178.0</td>\n      <td>8.639500e+13</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>79.0</td>\n    </tr>\n    <tr>\n      <th>994</th>\n      <td>40085.0</td>\n      <td>40085.0</td>\n      <td>40085.0</td>\n      <td>40085.0</td>\n      <td>40085.0</td>\n      <td>40085.0</td>\n      <td>40085.0</td>\n      <td>40085.0</td>\n      <td>40085.0</td>\n      <td>40085.0</td>\n      <td>...</td>\n      <td>0.999219</td>\n      <td>1.673958</td>\n      <td>88.629547</td>\n      <td>0.0</td>\n      <td>1875.199951</td>\n      <td>4183.0</td>\n      <td>8.639500e+13</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>342324.0</td>\n      <td>342324.0</td>\n      <td>342324.0</td>\n      <td>342324.0</td>\n      <td>342324.0</td>\n      <td>342324.0</td>\n      <td>342324.0</td>\n      <td>342324.0</td>\n      <td>342324.0</td>\n      <td>342324.0</td>\n      <td>...</td>\n      <td>1.006835</td>\n      <td>1.009104</td>\n      <td>88.652969</td>\n      <td>1.0</td>\n      <td>1196.599976</td>\n      <td>4176.0</td>\n      <td>8.639500e+13</td>\n      <td>7.0</td>\n      <td>4.0</td>\n      <td>20.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>996 rows × 96 columns</p>\n</div>"},"metadata":{}}],"execution_count":204},{"cell_type":"code","source":"# train_ts_encoded = perform_autoencoder(df_train, encoding_dim=60, epochs=100, batch_size=32)\n# test_ts_encoded = perform_autoencoder(df_test, encoding_dim=60, epochs=100, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:25:47.004107Z","iopub.execute_input":"2024-12-23T09:25:47.004330Z","iopub.status.idle":"2024-12-23T09:25:47.008176Z","shell.execute_reply.started":"2024-12-23T09:25:47.004306Z","shell.execute_reply":"2024-12-23T09:25:47.007286Z"}},"outputs":[],"execution_count":205},{"cell_type":"code","source":"time_series_cols = train_ts_encoded.columns.tolist() # lưu trữ các cột\ntrain_ts_encoded[\"id\"]=train_ts[\"id\"]\ntest_ts_encoded['id']=test_ts[\"id\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:25:47.009340Z","iopub.execute_input":"2024-12-23T09:25:47.009662Z","iopub.status.idle":"2024-12-23T09:25:47.019444Z","shell.execute_reply.started":"2024-12-23T09:25:47.009626Z","shell.execute_reply":"2024-12-23T09:25:47.018769Z"}},"outputs":[],"execution_count":206},{"cell_type":"markdown","source":"## CSV DATA PROCESSING","metadata":{}},{"cell_type":"markdown","source":"#### Drop any samplers which only missed any values in PCIAT test","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/child-mind-institute-problematic-internet-use/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/child-mind-institute-problematic-internet-use/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:25:47.020424Z","iopub.execute_input":"2024-12-23T09:25:47.020674Z","iopub.status.idle":"2024-12-23T09:25:47.063883Z","shell.execute_reply.started":"2024-12-23T09:25:47.020650Z","shell.execute_reply":"2024-12-23T09:25:47.063056Z"}},"outputs":[],"execution_count":207},{"cell_type":"code","source":"columns_not_in_test = ['PCIAT-PCIAT_01', 'PCIAT-PCIAT_02', 'PCIAT-PCIAT_03', 'PCIAT-PCIAT_04', 'PCIAT-PCIAT_05', 'PCIAT-PCIAT_06', 'PCIAT-PCIAT_07', 'PCIAT-PCIAT_08', 'PCIAT-PCIAT_09', 'PCIAT-PCIAT_10', 'PCIAT-PCIAT_11', 'PCIAT-PCIAT_12', 'PCIAT-PCIAT_13', 'PCIAT-PCIAT_14', 'PCIAT-PCIAT_15', 'PCIAT-PCIAT_16', 'PCIAT-PCIAT_17', 'PCIAT-PCIAT_18', 'PCIAT-PCIAT_19', 'PCIAT-PCIAT_20', 'PCIAT-PCIAT_Total', 'PCIAT-Season', 'sii']\ntrain_data = train_data.dropna(subset=columns_not_in_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:25:47.065078Z","iopub.execute_input":"2024-12-23T09:25:47.065398Z","iopub.status.idle":"2024-12-23T09:25:47.073792Z","shell.execute_reply.started":"2024-12-23T09:25:47.065361Z","shell.execute_reply":"2024-12-23T09:25:47.072721Z"}},"outputs":[],"execution_count":208},{"cell_type":"markdown","source":"#### Drop season data","metadata":{"execution":{"iopub.status.busy":"2024-12-16T07:14:27.674415Z","iopub.execute_input":"2024-12-16T07:14:27.674761Z","iopub.status.idle":"2024-12-16T07:14:27.678811Z","shell.execute_reply.started":"2024-12-16T07:14:27.674731Z","shell.execute_reply":"2024-12-16T07:14:27.677871Z"}}},{"cell_type":"code","source":"train_seasonal_columns = [col for col in train_data.columns if 'Season' in col]\ntest_seasonal_columns = [col for col in test_data.columns if 'Season' in col]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:25:47.075033Z","iopub.execute_input":"2024-12-23T09:25:47.075868Z","iopub.status.idle":"2024-12-23T09:25:47.089625Z","shell.execute_reply.started":"2024-12-23T09:25:47.075825Z","shell.execute_reply":"2024-12-23T09:25:47.088822Z"}},"outputs":[],"execution_count":209},{"cell_type":"code","source":"train_data_wo_season = train_data.drop(train_seasonal_columns, axis = 1)\ntest_data_wo_season = test_data.drop(test_seasonal_columns, axis = 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:25:47.093379Z","iopub.execute_input":"2024-12-23T09:25:47.093652Z","iopub.status.idle":"2024-12-23T09:25:47.102466Z","shell.execute_reply.started":"2024-12-23T09:25:47.093627Z","shell.execute_reply":"2024-12-23T09:25:47.101695Z"}},"outputs":[],"execution_count":210},{"cell_type":"markdown","source":"#### So, we got a quire reliable labels here, the next step would be create X and y","metadata":{}},{"cell_type":"code","source":"label_related_features = ['PCIAT-PCIAT_01', 'PCIAT-PCIAT_02', 'PCIAT-PCIAT_03', 'PCIAT-PCIAT_04', 'PCIAT-PCIAT_05', 'PCIAT-PCIAT_06', 'PCIAT-PCIAT_07', 'PCIAT-PCIAT_08', 'PCIAT-PCIAT_09', 'PCIAT-PCIAT_10', 'PCIAT-PCIAT_11', 'PCIAT-PCIAT_12', 'PCIAT-PCIAT_13', 'PCIAT-PCIAT_14', 'PCIAT-PCIAT_15', 'PCIAT-PCIAT_16', 'PCIAT-PCIAT_17', 'PCIAT-PCIAT_18', 'PCIAT-PCIAT_19', 'PCIAT-PCIAT_20', 'PCIAT-PCIAT_Total', 'sii']\nlabel = ['PCIAT-PCIAT_Total']\nX = train_data_wo_season.drop(label_related_features, axis = 1)\nnew_y = train_data_wo_season[label]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:27:56.907984Z","iopub.execute_input":"2024-12-23T09:27:56.908367Z","iopub.status.idle":"2024-12-23T09:27:56.915642Z","shell.execute_reply.started":"2024-12-23T09:27:56.908335Z","shell.execute_reply":"2024-12-23T09:27:56.914768Z"}},"outputs":[],"execution_count":212},{"cell_type":"code","source":"new_X = X.drop(['id'], axis = 1)\nnew_test = test_data_wo_season.drop(['id'], axis = 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:27:58.891170Z","iopub.execute_input":"2024-12-23T09:27:58.891508Z","iopub.status.idle":"2024-12-23T09:27:58.897577Z","shell.execute_reply.started":"2024-12-23T09:27:58.891477Z","shell.execute_reply":"2024-12-23T09:27:58.896532Z"}},"outputs":[],"execution_count":213},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstandard_scaler = StandardScaler()\n\nnew_X = pd.DataFrame(standard_scaler.fit_transform(new_X), columns=new_X.columns)\nnew_test = pd.DataFrame(standard_scaler.fit_transform(new_test), columns=new_test.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:28:00.065970Z","iopub.execute_input":"2024-12-23T09:28:00.066357Z","iopub.status.idle":"2024-12-23T09:28:00.083613Z","shell.execute_reply.started":"2024-12-23T09:28:00.066326Z","shell.execute_reply":"2024-12-23T09:28:00.082884Z"}},"outputs":[],"execution_count":214},{"cell_type":"markdown","source":"## IMPUTATION IN CSV DATA","metadata":{}},{"cell_type":"code","source":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:28:01.745702Z","iopub.execute_input":"2024-12-23T09:28:01.746529Z","iopub.status.idle":"2024-12-23T09:28:01.750467Z","shell.execute_reply.started":"2024-12-23T09:28:01.746491Z","shell.execute_reply":"2024-12-23T09:28:01.749540Z"}},"outputs":[],"execution_count":215},{"cell_type":"code","source":"def fill_na_with_MICE(df):\n    df_copy = df.copy()\n    missing_mask = df_copy.isna()\n    original_columns = df_copy.columns.tolist()\n    imputer = IterativeImputer(max_iter=50, random_state=0)\n    imputed_values = imputer.fit_transform(df_copy)\n    imputed_df = pd.DataFrame(\n        imputed_values,\n        columns=original_columns,\n        index=df_copy.index\n    )\n    df_copy[missing_mask] = imputed_df[missing_mask]\n    return df_copy\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:28:03.497743Z","iopub.execute_input":"2024-12-23T09:28:03.498420Z","iopub.status.idle":"2024-12-23T09:28:03.503202Z","shell.execute_reply.started":"2024-12-23T09:28:03.498385Z","shell.execute_reply":"2024-12-23T09:28:03.502347Z"}},"outputs":[],"execution_count":216},{"cell_type":"code","source":"new_X = fill_na_with_MICE(new_X)\nnew_test = fill_na_with_MICE(new_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:28:04.791458Z","iopub.execute_input":"2024-12-23T09:28:04.792734Z","iopub.status.idle":"2024-12-23T09:28:28.663519Z","shell.execute_reply.started":"2024-12-23T09:28:04.792694Z","shell.execute_reply":"2024-12-23T09:28:28.662513Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":217},{"cell_type":"markdown","source":"## MERGE PARQUET INTO TABULAR DATA","metadata":{}},{"cell_type":"code","source":"train_ts_encoded[\"id\"] = train_ts[\"id\"]\nnew_X['id'] =  train_data['id']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:28:28.665079Z","iopub.execute_input":"2024-12-23T09:28:28.665351Z","iopub.status.idle":"2024-12-23T09:28:28.671179Z","shell.execute_reply.started":"2024-12-23T09:28:28.665323Z","shell.execute_reply":"2024-12-23T09:28:28.670292Z"}},"outputs":[],"execution_count":218},{"cell_type":"code","source":"test_ts_encoded['id'] = test_ts['id']\nnew_test['id'] = test_data['id']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:28:28.672402Z","iopub.execute_input":"2024-12-23T09:28:28.673303Z","iopub.status.idle":"2024-12-23T09:28:28.682231Z","shell.execute_reply.started":"2024-12-23T09:28:28.673261Z","shell.execute_reply":"2024-12-23T09:28:28.681505Z"}},"outputs":[],"execution_count":219},{"cell_type":"code","source":"merged_train = pd.merge(new_X, train_ts_encoded, how='left', on = 'id')\nmerged_test = pd.merge(new_test, test_ts_encoded, how='left', on = 'id')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:28:28.683909Z","iopub.execute_input":"2024-12-23T09:28:28.684161Z","iopub.status.idle":"2024-12-23T09:28:28.700948Z","shell.execute_reply.started":"2024-12-23T09:28:28.684136Z","shell.execute_reply":"2024-12-23T09:28:28.700167Z"}},"outputs":[],"execution_count":220},{"cell_type":"markdown","source":"## AFTER MERGED, FILL NULL WITH MERGED DATA","metadata":{}},{"cell_type":"code","source":"merged_train_wo_id = merged_train.drop('id', axis = 1)\nmerged_test_wo_id = merged_test.drop('id', axis = 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:28:28.701933Z","iopub.execute_input":"2024-12-23T09:28:28.702221Z","iopub.status.idle":"2024-12-23T09:28:28.712535Z","shell.execute_reply.started":"2024-12-23T09:28:28.702197Z","shell.execute_reply":"2024-12-23T09:28:28.711858Z"}},"outputs":[],"execution_count":221},{"cell_type":"code","source":"new_merged_train.to_csv(\"new_merged_train.csv\", index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:28:28.713589Z","iopub.execute_input":"2024-12-23T09:28:28.713911Z","iopub.status.idle":"2024-12-23T09:28:28.847634Z","shell.execute_reply.started":"2024-12-23T09:28:28.713875Z","shell.execute_reply":"2024-12-23T09:28:28.846660Z"}},"outputs":[],"execution_count":222},{"cell_type":"code","source":"new_X = new_merged_train\nnew_test = new_merged_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:28:28.848920Z","iopub.execute_input":"2024-12-23T09:28:28.849301Z","iopub.status.idle":"2024-12-23T09:28:28.853816Z","shell.execute_reply.started":"2024-12-23T09:28:28.849260Z","shell.execute_reply":"2024-12-23T09:28:28.852957Z"}},"outputs":[],"execution_count":223},{"cell_type":"markdown","source":"## Helper functions","metadata":{}},{"cell_type":"code","source":"def get_info_for_ftt(df):\n    number_of_cat = 0\n    cat_ranges = []\n    all_features = df.columns.tolist()\n    cat_idx = []\n    for i, feature in enumerate(all_features):\n        if (df[feature].nunique() <= 2):\n            number_of_cat = number_of_cat + 1\n            cat_ranges.append(df[feature].nunique())\n            cat_idx.append(i)\n    \n    num_continuous = df.shape[-1] - number_of_cat\n    return cat_ranges, num_continuous, cat_idx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:28:28.855070Z","iopub.execute_input":"2024-12-23T09:28:28.855385Z","iopub.status.idle":"2024-12-23T09:28:28.865580Z","shell.execute_reply.started":"2024-12-23T09:28:28.855347Z","shell.execute_reply":"2024-12-23T09:28:28.864805Z"}},"outputs":[],"execution_count":224},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass MyDataset(Dataset):\n    def __init__(self, samples, labels, cat_idx):\n        if isinstance(labels, pd.DataFrame) or isinstance(labels, pd.Series):\n            labels = labels.to_numpy()\n        self.samples = samples\n        self.labels = labels\n        self.cat_idx = cat_idx\n        \n    def __len__(self):\n        return len(self.labels)\n        \n    def divide_cat_num(self, row_data):\n        mask = np.zeros(len(row_data), dtype=bool)\n        mask[self.cat_idx] = True\n        cat_elements = row_data[mask]\n        remaining_elements = row_data[~mask]\n        return cat_elements, remaining_elements\n\n    def __getitem__(self, idx):\n        row_value = self.samples[idx]\n        tensor_row_value = torch.tensor(row_value)\n        cat_values, num_values = self.divide_cat_num(row_value)\n        cat_values = torch.tensor(cat_values, dtype=torch.int32)\n        num_values = torch.tensor(num_values, dtype=torch.float32)\n        label = self.labels[idx]\n        tensor_label = torch.tensor(label, dtype=torch.float32) \n        return cat_values, num_values, tensor_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:28:28.866452Z","iopub.execute_input":"2024-12-23T09:28:28.866720Z","iopub.status.idle":"2024-12-23T09:28:28.877064Z","shell.execute_reply.started":"2024-12-23T09:28:28.866681Z","shell.execute_reply":"2024-12-23T09:28:28.876232Z"}},"outputs":[],"execution_count":225},{"cell_type":"code","source":"from torch.utils.data import DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:28:28.879380Z","iopub.execute_input":"2024-12-23T09:28:28.879629Z","iopub.status.idle":"2024-12-23T09:28:28.892589Z","shell.execute_reply.started":"2024-12-23T09:28:28.879604Z","shell.execute_reply":"2024-12-23T09:28:28.891753Z"}},"outputs":[],"execution_count":226},{"cell_type":"code","source":"!pip install /kaggle/input/fttransformer/einops-0.8.0-py3-none-any.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:28:28.893522Z","iopub.execute_input":"2024-12-23T09:28:28.893765Z","iopub.status.idle":"2024-12-23T09:29:09.044342Z","shell.execute_reply.started":"2024-12-23T09:28:28.893741Z","shell.execute_reply":"2024-12-23T09:29:09.043071Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\nIn addition, using fork() with Python in general is a recipe for mysterious\ndeadlocks and crashes.\n\nThe most likely reason you are seeing this error is because you are using the\nmultiprocessing module on Linux, which uses fork() by default. This will be\nfixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n\nSee https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Processing /kaggle/input/fttransformer/einops-0.8.0-py3-none-any.whl\neinops is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n","output_type":"stream"}],"execution_count":227},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:29:09.045975Z","iopub.execute_input":"2024-12-23T09:29:09.046304Z","iopub.status.idle":"2024-12-23T09:29:09.050903Z","shell.execute_reply.started":"2024-12-23T09:29:09.046273Z","shell.execute_reply":"2024-12-23T09:29:09.050040Z"}},"outputs":[],"execution_count":228},{"cell_type":"code","source":"cat_ranges, num_continuous, cat_idx = get_info_for_ftt(new_X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:29:09.052117Z","iopub.execute_input":"2024-12-23T09:29:09.052359Z","iopub.status.idle":"2024-12-23T09:29:09.071066Z","shell.execute_reply.started":"2024-12-23T09:29:09.052336Z","shell.execute_reply":"2024-12-23T09:29:09.070231Z"}},"outputs":[],"execution_count":229},{"cell_type":"markdown","source":"## Integration Batch Normalization","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch import nn, einsum\n\nfrom einops import rearrange, repeat\n\n### this class \n\nclass BatchNormSequence(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.bn = nn.BatchNorm1d(dim)\n        \n    def forward(self, x):\n        # x: (batch, sequence, features)\n        x = x.transpose(1, 2)\n        x = self.bn(x)\n        x = x.transpose(1, 2) \n        return x\n\n\nclass GEGLU(nn.Module):\n    def forward(self, x):\n        x, gates = x.chunk(2, dim = -1)\n        return x * F.gelu(gates)\n\ndef FeedForward(dim, mult = 4, dropout = 0.):\n    return nn.Sequential(\n        nn.LayerNorm(dim),\n        nn.Linear(dim, dim * mult * 2),\n        GEGLU(),\n        nn.Dropout(dropout),\n        nn.Linear(dim * mult, dim)\n    )\n\nclass Attention(nn.Module):\n    def __init__(\n        self,\n        dim,\n        heads = 8,\n        dim_head = 64,\n        dropout = 0.\n    ):\n        super().__init__()\n        inner_dim = dim_head * heads\n        self.heads = heads\n        self.scale = dim_head ** -0.5\n\n        self.norm = nn.LayerNorm(dim)\n        \n        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n        self.to_out = nn.Linear(inner_dim, dim, bias = False)\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        h = self.heads\n\n        x = self.norm(x)\n\n        q, k, v = self.to_qkv(x).chunk(3, dim = -1)\n        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n        q = q * self.scale\n\n        sim = einsum('b h i d, b h j d -> b h i j', q, k)\n\n        attn = sim.softmax(dim = -1)\n        dropped_attn = self.dropout(attn)\n\n        out = einsum('b h i j, b h j d -> b h i d', dropped_attn, v)\n        out = rearrange(out, 'b h n d -> b n (h d)', h = h)\n        out = self.to_out(out)\n\n        return out, attn\n\nclass Transformer(nn.Module):\n    def __init__(\n        self,\n        dim,\n        depth,\n        heads,\n        dim_head,\n        attn_dropout,\n        ff_dropout\n    ):\n        super().__init__()\n        self.layers = nn.ModuleList([])\n\n        for _ in range(depth):\n            self.layers.append(nn.ModuleList([\n                Attention(dim, heads = heads, dim_head = dim_head, dropout = attn_dropout),\n                FeedForward(dim, dropout = ff_dropout),\n            ]))\n\n    def forward(self, x, return_attn = False):\n        post_softmax_attns = []\n\n        for attn, ff in self.layers:\n            attn_out, post_softmax_attn = attn(x)\n            post_softmax_attns.append(post_softmax_attn)\n\n            x = attn_out + x\n            x = ff(x) + x\n\n        if not return_attn:\n            return x\n\n        return x, torch.stack(post_softmax_attns)\n        \n\n        \nclass NumericalEmbedder(nn.Module):\n    def __init__(self, dim, num_numerical_types):\n        super().__init__()\n        self.weights = nn.Parameter(torch.randn(num_numerical_types, dim))\n        self.biases = nn.Parameter(torch.randn(num_numerical_types, dim))\n\n    def forward(self, x):\n        x = rearrange(x, 'b n -> b n 1')\n        return x * self.weights + self.biases\n\n# main class\n\nclass FTTransformer(nn.Module):\n    def __init__(\n        self,\n        *,\n        categories,\n        num_continuous,\n        dim,\n        depth,\n        heads,\n        dim_head = 16,\n        dim_out = 1,\n        num_special_tokens = 2,\n        attn_dropout = 0.,\n        ff_dropout = 0.\n    ):\n        super().__init__()\n        assert all(map(lambda n: n > 0, categories)), 'number of each category must be positive'\n        assert len(categories) + num_continuous > 0, 'input shape must not be null'\n\n        # categories related calculations\n\n        self.num_categories = len(categories)\n        self.num_unique_categories = sum(categories)\n\n        # create category embeddings table\n\n        self.num_special_tokens = num_special_tokens\n        total_tokens = self.num_unique_categories + num_special_tokens\n\n        # for automatically offsetting unique category ids to the correct position in the categories embedding table\n\n        if self.num_unique_categories > 0:\n            categories_offset = F.pad(torch.tensor(list(categories)), (1, 0), value = num_special_tokens)\n            categories_offset = categories_offset.cumsum(dim = -1)[:-1]\n            self.register_buffer('categories_offset', categories_offset)\n\n            # categorical embedding\n\n            self.categorical_embeds = nn.Embedding(total_tokens, dim)\n            self.categ_bn = BatchNormSequence(dim)\n\n\n        # continuous\n\n        self.num_continuous = num_continuous\n\n        if self.num_continuous > 0:\n            self.numerical_embedder = NumericalEmbedder(dim, self.num_continuous)\n            self.numer_bn = BatchNormSequence(dim)\n\n\n        # cls token\n\n        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n        self.pre_transformer_bn = BatchNormSequence(dim)\n\n        # transformer\n\n        self.transformer = Transformer(\n            dim = dim,\n            depth = depth,\n            heads = heads,\n            dim_head = dim_head,\n            attn_dropout = attn_dropout,\n            ff_dropout = ff_dropout\n        )\n\n        # to logits\n\n        self.to_logits = nn.Sequential(\n            nn.LayerNorm(dim),\n            nn.ReLU(),\n            nn.Linear(dim, dim_out)\n        )\n\n    def forward(self, x_categ, x_numer, return_attn = False):\n        assert x_categ.shape[-1] == self.num_categories, f'you must pass in {self.num_categories} values for your categories input'\n\n        xs = []\n        if self.num_unique_categories > 0:\n            x_categ = x_categ + self.categories_offset\n\n            x_categ = self.categorical_embeds(x_categ)\n            x_categ = self.categ_bn(x_categ)\n            xs.append(x_categ)\n\n        # add numerically embedded tokens\n        if self.num_continuous > 0:\n            x_numer = self.numerical_embedder(x_numer)\n            x_numer = self.numer_bn(x_numer)\n            xs.append(x_numer)\n\n        # concat categorical and numerical\n\n        x = torch.cat(xs, dim = 1)\n        x = self.pre_transformer_bn(x)\n\n\n        # append cls tokens\n        b = x.shape[0]\n        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n        x = torch.cat((cls_tokens, x), dim = 1)\n        \n        # attend\n\n        x, attns = self.transformer(x, return_attn = True)\n\n        # get cls token\n\n        x = x[:, 0]\n\n        # out in the paper is linear(relu(ln(cls)))\n\n        logits = self.to_logits(x)\n\n        if not return_attn:\n            return logits\n\n        return logits, attns\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:29:09.072280Z","iopub.execute_input":"2024-12-23T09:29:09.072562Z","iopub.status.idle":"2024-12-23T09:29:09.095921Z","shell.execute_reply.started":"2024-12-23T09:29:09.072537Z","shell.execute_reply":"2024-12-23T09:29:09.095071Z"}},"outputs":[],"execution_count":230},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, RegressorMixin\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport os\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:29:09.098275Z","iopub.execute_input":"2024-12-23T09:29:09.098538Z","iopub.status.idle":"2024-12-23T09:29:09.110164Z","shell.execute_reply.started":"2024-12-23T09:29:09.098497Z","shell.execute_reply":"2024-12-23T09:29:09.109345Z"}},"outputs":[],"execution_count":231},{"cell_type":"code","source":"class FTTransformerWrapper(BaseEstimator, RegressorMixin):\n    def __init__(self, categories, num_continuous, dim, dim_out, depth, heads, attn_dropout, \n                 ff_dropout, batch_size, num_epochs, learning_rate, cat_ranges, cat_idx):\n        self.categories = categories\n        self.num_continuous = num_continuous\n        self.dim = dim\n        self.dim_out = dim_out\n        self.depth = depth\n        self.heads = heads\n        self.attn_dropout = attn_dropout\n        self.ff_dropout = ff_dropout\n        self.batch_size = batch_size\n        self.num_epochs = num_epochs\n        self.learning_rate = learning_rate\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.cat_ranges = cat_ranges\n        self.cat_idx = cat_idx\n        self.num_epochs = num_epochs\n        \n    def _init_model(self):\n        self.model = FTTransformer(\n            categories=self.categories,\n            num_continuous=self.num_continuous,\n            dim=self.dim,\n            dim_out=self.dim_out,\n            depth=self.depth,\n            heads=self.heads,\n            attn_dropout=self.attn_dropout,\n            ff_dropout=self.ff_dropout\n        ).to(self.device)\n        self.criterion = torch.nn.MSELoss()\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n\n    def fit(self, X, y):\n        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n        train_dataset = MyDataset(X_train.values, y_train, self.cat_idx)\n        val_dataset = MyDataset(X_val.values, y_val, self.cat_idx)\n        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n\n        self._init_model()\n        best_val_loss = float('inf')\n\n        save_path='model_checkpoints'\n        os.makedirs(save_path, exist_ok=True)\n\n        for epoch in range(self.num_epochs):\n            self.model.train()\n            train_loss = 0\n            for x_cat, x_num, y in train_loader:\n                x_cat = x_cat.to(self.device) if x_cat is not None else None\n                x_num = x_num.to(self.device)\n                y = y.to(self.device)\n\n                self.optimizer.zero_grad()\n                output = self.model(x_cat, x_num).squeeze(1)\n                \n                loss = self.criterion(output, y)\n                loss.backward()\n                self.optimizer.step()\n                train_loss += loss.item()\n            \n            self.model.eval()\n            val_loss = 0\n            with torch.no_grad():\n                for x_cat, x_num, y in val_loader:\n                    x_cat = x_cat.to(self.device) if x_cat is not None else None\n                    x_num = x_num.to(self.device)\n                    y = y.to(self.device)\n                    \n                    output = self.model(x_cat, x_num).squeeze(1)\n\n                    val_loss += self.criterion(output, y).item()\n\n            avg_train_loss = train_loss / len(train_loader)\n            avg_val_loss = val_loss / len(val_loader)\n            print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n\n            if avg_val_loss < best_val_loss:\n                best_val_loss = avg_val_loss\n                checkpoint = {\n                    'epoch': epoch,\n                    'model_state_dict': self.model.state_dict(),\n                    'optimizer_state_dict': self.optimizer.state_dict(),\n                    'train_loss': avg_train_loss,\n                    'val_loss': avg_val_loss,\n                    'best_val_loss': best_val_loss\n                }\n                torch.save(checkpoint, os.path.join(save_path, f'best_model.pth'))\n                print(f'Saved best model with validation loss: {best_val_loss:.4f}')\n\n    def load_model(self, model, checkpoint_path):\n        checkpoint = torch.load(checkpoint_path)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        return model\n\n    def load_model_checkpoint(self, checkpoint_path):\n        try:\n            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n            self.model.load_state_dict(checkpoint['model_state_dict'])\n            self.model.to(self.device)\n            self.model.eval()\n            print(f\"Model loaded from {checkpoint_path}\")\n        except Exception as e:\n            print(f\"Error loading the model: {e}\")\n    \n    def predict(self, X):\n        self.model = self.load_model(self.model, \"/kaggle/working/model_checkpoints/best_model.pth\")\n\n        def divide_cat_num(data, cat_idx):\n            mask = np.zeros(data.shape[1], dtype=bool)\n            mask[cat_idx] = True\n            cat_elements = data[:, mask]\n            remaining_elements = data[:, ~mask]\n            return cat_elements, remaining_elements\n\n        self.model.eval()\n        new_test_values = X.values\n        num_samples = len(new_test_values)\n        predictions = []\n\n        for i in range(0, num_samples, self.batch_size):\n            batch_data = new_test_values[i:i + self.batch_size]\n            cat, num = divide_cat_num(batch_data, self.cat_idx)\n            cat = torch.tensor(cat, dtype=torch.int32).to(self.device)\n            num = torch.tensor(num, dtype=torch.float32).to(self.device)\n\n            with torch.no_grad():\n                output = self.model(cat, num)\n                output = output.squeeze(1)\n                predictions.extend(output.cpu().numpy())\n\n            del cat\n            del num\n            del output\n            torch.cuda.empty_cache()\n\n        return np.array(predictions)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:29:09.111346Z","iopub.execute_input":"2024-12-23T09:29:09.111589Z","iopub.status.idle":"2024-12-23T09:29:09.130099Z","shell.execute_reply.started":"2024-12-23T09:29:09.111565Z","shell.execute_reply":"2024-12-23T09:29:09.129159Z"}},"outputs":[],"execution_count":232},{"cell_type":"markdown","source":"## Hyper Finetuning FTTransformer using Grid search","metadata":{"execution":{"iopub.status.busy":"2024-12-22T16:58:49.222237Z","iopub.execute_input":"2024-12-22T16:58:49.222587Z","iopub.status.idle":"2024-12-22T16:58:49.226329Z","shell.execute_reply.started":"2024-12-22T16:58:49.222555Z","shell.execute_reply":"2024-12-22T16:58:49.225462Z"}}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer, mean_squared_error\nimport numpy as np\nfrom sklearn.metrics import make_scorer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:32:15.661639Z","iopub.execute_input":"2024-12-23T09:32:15.662508Z","iopub.status.idle":"2024-12-23T09:32:15.666642Z","shell.execute_reply.started":"2024-12-23T09:32:15.662471Z","shell.execute_reply":"2024-12-23T09:32:15.665656Z"}},"outputs":[],"execution_count":241},{"cell_type":"code","source":"param_grid = {\n    'dim': [8, 16, 32],\n    'depth': [2, 3],\n    'heads': [2, 4],\n    'learning_rate': [1e-2,1e-3, 1e-4],\n    'attn_dropout': [0.1, 0.2],\n    'ff_dropout': [0.1, 0.2],\n}\n\nfixed_params = {\n    'categories': tuple(cat_ranges),\n    'num_continuous': num_continuous,\n    'dim_out': 1,\n    'cat_ranges': cat_ranges,\n    'cat_idx': cat_idx,\n    'learning_rate': [1e-3],\n    'num_epochs': [70],\n    'batch_size': [32],\n\n}\nbase_params = {\n    'dim': param_grid['dim'][0],  \n    'depth': param_grid['depth'][0],\n    'heads': param_grid['heads'][0],\n}\nfull_params = {**fixed_params, **base_params}\nmse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n\ngrid_search = GridSearchCV(\n    estimator=FTTransformerWrapper(**full_params),\n    param_grid=param_grid,\n    scoring=mse_scorer,\n    cv=3,\n    n_jobs=-1,\n    verbose=2\n)\ngrid_search.fit(new_X, new_y)\nprint(\"Best parameters:\", grid_search.best_params_)\nprint(\"Best score:\", -grid_search.best_score_) \nbest_params = grid_search.best_params_\nftt_params.update(best_params)\nFTT_Model = FTTransformerWrapper(**ftt_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T09:35:48.648508Z","iopub.execute_input":"2024-12-23T09:35:48.649344Z","iopub.status.idle":"2024-12-23T09:35:53.414475Z","shell.execute_reply.started":"2024-12-23T09:35:48.649293Z","shell.execute_reply":"2024-12-23T09:35:53.413004Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Best Params is with following \n    'dim': 16,             \n    'dim_out': 1,          \n    'depth': 2,            \n    'heads': 3,            \n    'attn_dropout': 0.1,   \n    'ff_dropout': 0.2,\n    ","metadata":{}},{"cell_type":"code","source":"ftt_params = {\n    'categories': tuple(cat_ranges), \n    'num_continuous': num_continuous,    \n    'dim': 16,             \n    'dim_out': 1,          \n    'depth': 2,            \n    'heads': 3,            \n    'attn_dropout': 0.1,   \n    'ff_dropout': 0.2,\n    'batch_size': 32,\n    'num_epochs': 70,\n    'learning_rate': 0.001,\n    'cat_ranges': cat_ranges,\n    'cat_idx': cat_idx \n}\nFTT_Model = FTTransformerWrapper(**ftt_params)\nFTT_Model.fit(new_X, new_y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:11:02.587089Z","iopub.execute_input":"2024-12-23T10:11:02.587812Z","iopub.status.idle":"2024-12-23T10:11:45.578610Z","shell.execute_reply.started":"2024-12-23T10:11:02.587779Z","shell.execute_reply":"2024-12-23T10:11:45.577663Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Train Loss: 1127.0181, Val Loss: 1054.8391\nSaved best model with validation loss: 1054.8391\nEpoch 2, Train Loss: 1085.8512, Val Loss: 1002.4052\nSaved best model with validation loss: 1002.4052\nEpoch 3, Train Loss: 1039.9228, Val Loss: 967.5619\nSaved best model with validation loss: 967.5619\nEpoch 4, Train Loss: 991.7312, Val Loss: 923.2894\nSaved best model with validation loss: 923.2894\nEpoch 5, Train Loss: 937.9290, Val Loss: 858.8305\nSaved best model with validation loss: 858.8305\nEpoch 6, Train Loss: 880.2088, Val Loss: 800.5455\nSaved best model with validation loss: 800.5455\nEpoch 7, Train Loss: 823.6019, Val Loss: 752.6921\nSaved best model with validation loss: 752.6921\nEpoch 8, Train Loss: 767.0167, Val Loss: 697.4572\nSaved best model with validation loss: 697.4572\nEpoch 9, Train Loss: 711.3331, Val Loss: 650.7777\nSaved best model with validation loss: 650.7777\nEpoch 10, Train Loss: 658.8650, Val Loss: 607.0153\nSaved best model with validation loss: 607.0153\nEpoch 11, Train Loss: 613.5032, Val Loss: 560.0558\nSaved best model with validation loss: 560.0558\nEpoch 12, Train Loss: 569.5563, Val Loss: 523.7897\nSaved best model with validation loss: 523.7897\nEpoch 13, Train Loss: 533.1300, Val Loss: 496.5564\nSaved best model with validation loss: 496.5564\nEpoch 14, Train Loss: 503.2869, Val Loss: 471.9773\nSaved best model with validation loss: 471.9773\nEpoch 15, Train Loss: 479.1886, Val Loss: 450.0490\nSaved best model with validation loss: 450.0490\nEpoch 16, Train Loss: 458.4041, Val Loss: 432.1821\nSaved best model with validation loss: 432.1821\nEpoch 17, Train Loss: 445.0521, Val Loss: 425.4745\nSaved best model with validation loss: 425.4745\nEpoch 18, Train Loss: 433.1419, Val Loss: 422.6565\nSaved best model with validation loss: 422.6565\nEpoch 19, Train Loss: 426.2125, Val Loss: 412.8591\nSaved best model with validation loss: 412.8591\nEpoch 20, Train Loss: 420.1294, Val Loss: 411.0588\nSaved best model with validation loss: 411.0588\nEpoch 21, Train Loss: 417.0852, Val Loss: 408.2173\nSaved best model with validation loss: 408.2173\nEpoch 22, Train Loss: 414.7728, Val Loss: 407.3611\nSaved best model with validation loss: 407.3611\nEpoch 23, Train Loss: 414.0595, Val Loss: 406.1881\nSaved best model with validation loss: 406.1881\nEpoch 24, Train Loss: 413.0831, Val Loss: 405.6257\nSaved best model with validation loss: 405.6257\nEpoch 25, Train Loss: 412.4029, Val Loss: 408.3698\nEpoch 26, Train Loss: 412.2965, Val Loss: 405.8351\nEpoch 27, Train Loss: 412.2801, Val Loss: 408.6819\nEpoch 28, Train Loss: 412.0386, Val Loss: 411.4204\nEpoch 29, Train Loss: 411.3109, Val Loss: 412.7486\nEpoch 30, Train Loss: 412.1657, Val Loss: 407.2174\nEpoch 31, Train Loss: 411.5626, Val Loss: 406.4814\nEpoch 32, Train Loss: 411.5468, Val Loss: 407.0009\nEpoch 33, Train Loss: 411.8115, Val Loss: 406.2280\nEpoch 34, Train Loss: 411.8522, Val Loss: 411.6881\nEpoch 35, Train Loss: 411.7676, Val Loss: 408.4310\nEpoch 36, Train Loss: 412.7649, Val Loss: 410.5472\nEpoch 37, Train Loss: 412.0522, Val Loss: 409.8538\nEpoch 38, Train Loss: 412.1637, Val Loss: 407.8294\nEpoch 39, Train Loss: 411.7094, Val Loss: 408.1395\nEpoch 40, Train Loss: 411.8871, Val Loss: 408.4301\nEpoch 41, Train Loss: 411.2597, Val Loss: 408.9601\nEpoch 42, Train Loss: 411.6000, Val Loss: 409.1803\nEpoch 43, Train Loss: 411.9335, Val Loss: 408.1258\nEpoch 44, Train Loss: 411.7445, Val Loss: 409.6376\nEpoch 45, Train Loss: 411.6984, Val Loss: 406.3219\nEpoch 46, Train Loss: 411.3635, Val Loss: 411.6443\nEpoch 47, Train Loss: 412.3165, Val Loss: 408.9628\nEpoch 48, Train Loss: 412.2196, Val Loss: 408.3909\nEpoch 49, Train Loss: 411.6198, Val Loss: 411.1436\nEpoch 50, Train Loss: 412.6239, Val Loss: 411.8002\nEpoch 51, Train Loss: 411.8398, Val Loss: 410.6851\nEpoch 52, Train Loss: 411.5868, Val Loss: 407.8436\nEpoch 53, Train Loss: 412.3567, Val Loss: 409.3048\nEpoch 54, Train Loss: 411.9177, Val Loss: 409.4710\nEpoch 55, Train Loss: 411.6170, Val Loss: 411.6379\nEpoch 56, Train Loss: 411.7364, Val Loss: 408.6013\nEpoch 57, Train Loss: 412.3624, Val Loss: 409.1259\nEpoch 58, Train Loss: 411.9218, Val Loss: 408.6104\nEpoch 59, Train Loss: 411.3671, Val Loss: 410.0807\nEpoch 60, Train Loss: 412.4873, Val Loss: 411.6792\nEpoch 61, Train Loss: 412.3944, Val Loss: 406.2849\nEpoch 62, Train Loss: 412.1809, Val Loss: 406.0852\nEpoch 63, Train Loss: 411.2362, Val Loss: 407.6723\nEpoch 64, Train Loss: 412.7629, Val Loss: 408.3962\nEpoch 65, Train Loss: 411.4814, Val Loss: 409.6343\nEpoch 66, Train Loss: 411.2206, Val Loss: 407.4860\nEpoch 67, Train Loss: 412.3935, Val Loss: 411.1697\nEpoch 68, Train Loss: 411.7581, Val Loss: 405.7283\nEpoch 69, Train Loss: 411.9576, Val Loss: 409.0253\nEpoch 70, Train Loss: 411.5663, Val Loss: 410.3127\n","output_type":"stream"}],"execution_count":246},{"cell_type":"code","source":"prediction = FTT_Model.predict(new_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:15:02.510375Z","iopub.execute_input":"2024-12-23T10:15:02.510720Z","iopub.status.idle":"2024-12-23T10:15:02.538143Z","shell.execute_reply.started":"2024-12-23T10:15:02.510688Z","shell.execute_reply":"2024-12-23T10:15:02.537343Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/2249404707.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path)\n","output_type":"stream"}],"execution_count":255},{"cell_type":"code","source":"test_id = test_data['id']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:15:04.181162Z","iopub.execute_input":"2024-12-23T10:15:04.181504Z","iopub.status.idle":"2024-12-23T10:15:04.185637Z","shell.execute_reply.started":"2024-12-23T10:15:04.181472Z","shell.execute_reply":"2024-12-23T10:15:04.184610Z"}},"outputs":[],"execution_count":256},{"cell_type":"code","source":"def handle_prediction(predictions, test_id):\n    # return submission.csv\n    sii = []\n    for i in range(len(predictions)):\n        predict = predictions[i]\n        if (predict >=  0 and predict <= 30):\n            sii.append(0)\n        elif(predict < 50):\n            sii.append(1)\n        elif(predict < 80):\n            sii.append(2)\n        else:\n            sii.append(3)\n    sii = pd.DataFrame(sii)\n    submission = pd.concat([test_id, sii], axis = 1)\n    submission = submission.rename(columns={0: 'sii'})\n    return submission\nsubmission = handle_prediction(prediction, test_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:15:06.110911Z","iopub.execute_input":"2024-12-23T10:15:06.111267Z","iopub.status.idle":"2024-12-23T10:15:06.119672Z","shell.execute_reply.started":"2024-12-23T10:15:06.111236Z","shell.execute_reply":"2024-12-23T10:15:06.118813Z"}},"outputs":[],"execution_count":257},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index = False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}