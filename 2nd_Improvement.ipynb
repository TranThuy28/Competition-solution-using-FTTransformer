{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "117fa6f1",
   "metadata": {},
   "source": [
    "## Second improvement (Parquet file integration, and features engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a639ba",
   "metadata": {
    "papermill": {
     "duration": 0.012193,
     "end_time": "2024-12-18T23:57:52.562246",
     "exception": false,
     "start_time": "2024-12-18T23:57:52.550053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PARQUET file processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "692f2de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:57:52.583508Z",
     "iopub.status.busy": "2024-12-18T23:57:52.583254Z",
     "iopub.status.idle": "2024-12-18T23:57:57.479743Z",
     "shell.execute_reply": "2024-12-18T23:57:57.478889Z"
    },
    "papermill": {
     "duration": 4.909213,
     "end_time": "2024-12-18T23:57:57.481723",
     "exception": false,
     "start_time": "2024-12-18T23:57:52.572510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.optim as optim\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70720cbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:57:57.514660Z",
     "iopub.status.busy": "2024-12-18T23:57:57.513929Z",
     "iopub.status.idle": "2024-12-18T23:57:57.521325Z",
     "shell.execute_reply": "2024-12-18T23:57:57.520071Z"
    },
    "papermill": {
     "duration": 0.022404,
     "end_time": "2024-12-18T23:57:57.523889",
     "exception": false,
     "start_time": "2024-12-18T23:57:57.501485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_file(filename, dirname):\n",
    "    \n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "\n",
    "    ids = os.listdir(dirname)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    stats, indexes = zip(*results)\n",
    "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a28ce83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:57:57.561720Z",
     "iopub.status.busy": "2024-12-18T23:57:57.561419Z",
     "iopub.status.idle": "2024-12-18T23:59:08.425160Z",
     "shell.execute_reply": "2024-12-18T23:59:08.424285Z"
    },
    "papermill": {
     "duration": 70.88582,
     "end_time": "2024-12-18T23:59:08.426876",
     "exception": false,
     "start_time": "2024-12-18T23:57:57.541056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:10<00:00, 14.10it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 11.93it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446d8fca",
   "metadata": {
    "papermill": {
     "duration": 0.024257,
     "end_time": "2024-12-18T23:59:08.475983",
     "exception": false,
     "start_time": "2024-12-18T23:59:08.451726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### fill parquet with autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b00f68c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:08.526069Z",
     "iopub.status.busy": "2024-12-18T23:59:08.525766Z",
     "iopub.status.idle": "2024-12-18T23:59:08.531692Z",
     "shell.execute_reply": "2024-12-18T23:59:08.530888Z"
    },
    "papermill": {
     "duration": 0.032479,
     "end_time": "2024-12-18T23:59:08.533339",
     "exception": false,
     "start_time": "2024-12-18T23:59:08.500860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoding_dim*3),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(encoding_dim*3, encoding_dim*2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(encoding_dim*2, encoding_dim),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, input_dim*2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(input_dim*2, input_dim*3),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(input_dim*3, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce75c3fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:08.583122Z",
     "iopub.status.busy": "2024-12-18T23:59:08.582873Z",
     "iopub.status.idle": "2024-12-18T23:59:08.589356Z",
     "shell.execute_reply": "2024-12-18T23:59:08.588678Z"
    },
    "papermill": {
     "duration": 0.032806,
     "end_time": "2024-12-18T23:59:08.590777",
     "exception": false,
     "start_time": "2024-12-18T23:59:08.557971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perform_autoencoder(df, encoding_dim=50, epochs=50, batch_size=32):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "    \n",
    "    data_tensor = torch.FloatTensor(df_scaled)\n",
    "    \n",
    "    input_dim = data_tensor.shape[1]\n",
    "    autoencoder = AutoEncoder(input_dim, encoding_dim)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(autoencoder.parameters())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(data_tensor), batch_size):\n",
    "            batch = data_tensor[i : i + batch_size]\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed = autoencoder(batch)\n",
    "            loss = criterion(reconstructed, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}]')\n",
    "                 \n",
    "    with torch.no_grad():\n",
    "        encoded_data = autoencoder.encoder(data_tensor).numpy()\n",
    "        \n",
    "    df_encoded = pd.DataFrame(encoded_data, columns=[f'Enc_{i + 1}' for i in range(encoded_data.shape[1])])\n",
    "    \n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ed1ba03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:08.643881Z",
     "iopub.status.busy": "2024-12-18T23:59:08.643606Z",
     "iopub.status.idle": "2024-12-18T23:59:08.677713Z",
     "shell.execute_reply": "2024-12-18T23:59:08.676838Z"
    },
    "papermill": {
     "duration": 0.06181,
     "end_time": "2024-12-18T23:59:08.679305",
     "exception": false,
     "start_time": "2024-12-18T23:59:08.617495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stat_0</th>\n",
       "      <th>stat_1</th>\n",
       "      <th>stat_2</th>\n",
       "      <th>stat_3</th>\n",
       "      <th>stat_4</th>\n",
       "      <th>stat_5</th>\n",
       "      <th>stat_6</th>\n",
       "      <th>stat_7</th>\n",
       "      <th>stat_8</th>\n",
       "      <th>stat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>stat_86</th>\n",
       "      <th>stat_87</th>\n",
       "      <th>stat_88</th>\n",
       "      <th>stat_89</th>\n",
       "      <th>stat_90</th>\n",
       "      <th>stat_91</th>\n",
       "      <th>stat_92</th>\n",
       "      <th>stat_93</th>\n",
       "      <th>stat_94</th>\n",
       "      <th>stat_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50458.0</td>\n",
       "      <td>50458.0</td>\n",
       "      <td>50458.0</td>\n",
       "      <td>50458.0</td>\n",
       "      <td>50458.0</td>\n",
       "      <td>50458.0</td>\n",
       "      <td>50458.0</td>\n",
       "      <td>50458.0</td>\n",
       "      <td>50458.0</td>\n",
       "      <td>50458.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.738203</td>\n",
       "      <td>5.314874</td>\n",
       "      <td>89.422226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2626.199951</td>\n",
       "      <td>4187.0</td>\n",
       "      <td>8.639500e+13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>340584.0</td>\n",
       "      <td>340584.0</td>\n",
       "      <td>340584.0</td>\n",
       "      <td>340584.0</td>\n",
       "      <td>340584.0</td>\n",
       "      <td>340584.0</td>\n",
       "      <td>340584.0</td>\n",
       "      <td>340584.0</td>\n",
       "      <td>340584.0</td>\n",
       "      <td>340584.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.475326</td>\n",
       "      <td>3.966906</td>\n",
       "      <td>89.080330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2628.199951</td>\n",
       "      <td>4146.0</td>\n",
       "      <td>8.639500e+13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40003.0</td>\n",
       "      <td>40003.0</td>\n",
       "      <td>40003.0</td>\n",
       "      <td>40003.0</td>\n",
       "      <td>40003.0</td>\n",
       "      <td>40003.0</td>\n",
       "      <td>40003.0</td>\n",
       "      <td>40003.0</td>\n",
       "      <td>40003.0</td>\n",
       "      <td>40003.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.746797</td>\n",
       "      <td>5.066334</td>\n",
       "      <td>86.987267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2618.199951</td>\n",
       "      <td>4183.0</td>\n",
       "      <td>8.636500e+13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>223915.0</td>\n",
       "      <td>223915.0</td>\n",
       "      <td>223915.0</td>\n",
       "      <td>223915.0</td>\n",
       "      <td>223915.0</td>\n",
       "      <td>223915.0</td>\n",
       "      <td>223915.0</td>\n",
       "      <td>223915.0</td>\n",
       "      <td>223915.0</td>\n",
       "      <td>223915.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.269051</td>\n",
       "      <td>6.134459</td>\n",
       "      <td>89.976074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2502.000000</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>8.639500e+13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15420.0</td>\n",
       "      <td>15420.0</td>\n",
       "      <td>15420.0</td>\n",
       "      <td>15420.0</td>\n",
       "      <td>15420.0</td>\n",
       "      <td>15420.0</td>\n",
       "      <td>15420.0</td>\n",
       "      <td>15420.0</td>\n",
       "      <td>15420.0</td>\n",
       "      <td>15420.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.071875</td>\n",
       "      <td>2.774382</td>\n",
       "      <td>89.300034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1046.800049</td>\n",
       "      <td>4199.0</td>\n",
       "      <td>8.601500e+13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>394128.0</td>\n",
       "      <td>394128.0</td>\n",
       "      <td>394128.0</td>\n",
       "      <td>394128.0</td>\n",
       "      <td>394128.0</td>\n",
       "      <td>394128.0</td>\n",
       "      <td>394128.0</td>\n",
       "      <td>394128.0</td>\n",
       "      <td>394128.0</td>\n",
       "      <td>394128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.099614</td>\n",
       "      <td>3.669502</td>\n",
       "      <td>89.025551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2576.399902</td>\n",
       "      <td>4191.0</td>\n",
       "      <td>8.639500e+13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1195.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996484</td>\n",
       "      <td>1.786410</td>\n",
       "      <td>81.665283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1526.599976</td>\n",
       "      <td>4194.0</td>\n",
       "      <td>8.514000e+13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>393240.0</td>\n",
       "      <td>393240.0</td>\n",
       "      <td>393240.0</td>\n",
       "      <td>393240.0</td>\n",
       "      <td>393240.0</td>\n",
       "      <td>393240.0</td>\n",
       "      <td>393240.0</td>\n",
       "      <td>393240.0</td>\n",
       "      <td>393240.0</td>\n",
       "      <td>393240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.547813</td>\n",
       "      <td>3.692727</td>\n",
       "      <td>89.333710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2592.199951</td>\n",
       "      <td>4178.0</td>\n",
       "      <td>8.639500e+13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>40085.0</td>\n",
       "      <td>40085.0</td>\n",
       "      <td>40085.0</td>\n",
       "      <td>40085.0</td>\n",
       "      <td>40085.0</td>\n",
       "      <td>40085.0</td>\n",
       "      <td>40085.0</td>\n",
       "      <td>40085.0</td>\n",
       "      <td>40085.0</td>\n",
       "      <td>40085.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>1.673958</td>\n",
       "      <td>88.629547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1875.199951</td>\n",
       "      <td>4183.0</td>\n",
       "      <td>8.639500e+13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>342324.0</td>\n",
       "      <td>342324.0</td>\n",
       "      <td>342324.0</td>\n",
       "      <td>342324.0</td>\n",
       "      <td>342324.0</td>\n",
       "      <td>342324.0</td>\n",
       "      <td>342324.0</td>\n",
       "      <td>342324.0</td>\n",
       "      <td>342324.0</td>\n",
       "      <td>342324.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006835</td>\n",
       "      <td>1.009104</td>\n",
       "      <td>88.652969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1196.599976</td>\n",
       "      <td>4176.0</td>\n",
       "      <td>8.639500e+13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stat_0    stat_1    stat_2    stat_3    stat_4    stat_5    stat_6  \\\n",
       "0     50458.0   50458.0   50458.0   50458.0   50458.0   50458.0   50458.0   \n",
       "1    340584.0  340584.0  340584.0  340584.0  340584.0  340584.0  340584.0   \n",
       "2     40003.0   40003.0   40003.0   40003.0   40003.0   40003.0   40003.0   \n",
       "3    223915.0  223915.0  223915.0  223915.0  223915.0  223915.0  223915.0   \n",
       "4     15420.0   15420.0   15420.0   15420.0   15420.0   15420.0   15420.0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "991  394128.0  394128.0  394128.0  394128.0  394128.0  394128.0  394128.0   \n",
       "992    1195.0    1195.0    1195.0    1195.0    1195.0    1195.0    1195.0   \n",
       "993  393240.0  393240.0  393240.0  393240.0  393240.0  393240.0  393240.0   \n",
       "994   40085.0   40085.0   40085.0   40085.0   40085.0   40085.0   40085.0   \n",
       "995  342324.0  342324.0  342324.0  342324.0  342324.0  342324.0  342324.0   \n",
       "\n",
       "       stat_7    stat_8    stat_9  ...   stat_86   stat_87    stat_88  \\\n",
       "0     50458.0   50458.0   50458.0  ...  1.738203  5.314874  89.422226   \n",
       "1    340584.0  340584.0  340584.0  ...  2.475326  3.966906  89.080330   \n",
       "2     40003.0   40003.0   40003.0  ...  1.746797  5.066334  86.987267   \n",
       "3    223915.0  223915.0  223915.0  ...  1.269051  6.134459  89.976074   \n",
       "4     15420.0   15420.0   15420.0  ...  1.071875  2.774382  89.300034   \n",
       "..        ...       ...       ...  ...       ...       ...        ...   \n",
       "991  394128.0  394128.0  394128.0  ...  2.099614  3.669502  89.025551   \n",
       "992    1195.0    1195.0    1195.0  ...  0.996484  1.786410  81.665283   \n",
       "993  393240.0  393240.0  393240.0  ...  1.547813  3.692727  89.333710   \n",
       "994   40085.0   40085.0   40085.0  ...  0.999219  1.673958  88.629547   \n",
       "995  342324.0  342324.0  342324.0  ...  1.006835  1.009104  88.652969   \n",
       "\n",
       "     stat_89      stat_90  stat_91       stat_92  stat_93  stat_94  stat_95  \n",
       "0        0.0  2626.199951   4187.0  8.639500e+13      7.0      2.0     57.0  \n",
       "1        1.0  2628.199951   4146.0  8.639500e+13      7.0      2.0    243.0  \n",
       "2        0.0  2618.199951   4183.0  8.636500e+13      7.0      3.0    134.0  \n",
       "3        0.0  2502.000000   6000.0  8.639500e+13      7.0      4.0     72.0  \n",
       "4        0.0  1046.800049   4199.0  8.601500e+13      7.0      4.0     76.0  \n",
       "..       ...          ...      ...           ...      ...      ...      ...  \n",
       "991      1.0  2576.399902   4191.0  8.639500e+13      7.0      4.0    161.0  \n",
       "992      0.0  1526.599976   4194.0  8.514000e+13      7.0      2.0    130.0  \n",
       "993      1.0  2592.199951   4178.0  8.639500e+13      7.0      1.0     79.0  \n",
       "994      0.0  1875.199951   4183.0  8.639500e+13      7.0      1.0    155.0  \n",
       "995      1.0  1196.599976   4176.0  8.639500e+13      7.0      4.0     20.0  \n",
       "\n",
       "[996 rows x 96 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = train_ts.drop('id', axis=1)\n",
    "df_test = test_ts.drop('id', axis=1)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d21ca970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:08.731598Z",
     "iopub.status.busy": "2024-12-18T23:59:08.731323Z",
     "iopub.status.idle": "2024-12-18T23:59:19.365339Z",
     "shell.execute_reply": "2024-12-18T23:59:19.364256Z"
    },
    "papermill": {
     "duration": 10.662204,
     "end_time": "2024-12-18T23:59:19.367365",
     "exception": false,
     "start_time": "2024-12-18T23:59:08.705161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.4428]\n",
      "Epoch [20/100], Loss: 1.4151]\n",
      "Epoch [30/100], Loss: 1.3924]\n",
      "Epoch [40/100], Loss: 1.3862]\n",
      "Epoch [50/100], Loss: 1.3879]\n",
      "Epoch [60/100], Loss: 1.3818]\n",
      "Epoch [70/100], Loss: 1.3585]\n",
      "Epoch [80/100], Loss: 1.3560]\n",
      "Epoch [90/100], Loss: 1.3535]\n",
      "Epoch [100/100], Loss: 1.3559]\n",
      "Epoch [10/100], Loss: 1.0197]\n",
      "Epoch [20/100], Loss: 0.4461]\n",
      "Epoch [30/100], Loss: 0.4271]\n",
      "Epoch [40/100], Loss: 0.4271]\n",
      "Epoch [50/100], Loss: 0.4271]\n",
      "Epoch [60/100], Loss: 0.4271]\n",
      "Epoch [70/100], Loss: 0.4271]\n",
      "Epoch [80/100], Loss: 0.4271]\n",
      "Epoch [90/100], Loss: 0.4271]\n",
      "Epoch [100/100], Loss: 0.4271]\n"
     ]
    }
   ],
   "source": [
    "train_ts_encoded = perform_autoencoder(df_train, encoding_dim=60, epochs=100, batch_size=32)\n",
    "test_ts_encoded = perform_autoencoder(df_test, encoding_dim=60, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d62b13ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:19.424794Z",
     "iopub.status.busy": "2024-12-18T23:59:19.423807Z",
     "iopub.status.idle": "2024-12-18T23:59:19.429736Z",
     "shell.execute_reply": "2024-12-18T23:59:19.429028Z"
    },
    "papermill": {
     "duration": 0.033665,
     "end_time": "2024-12-18T23:59:19.431312",
     "exception": false,
     "start_time": "2024-12-18T23:59:19.397647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_series_cols = train_ts_encoded.columns.tolist() # lưu trữ các cột\n",
    "train_ts_encoded[\"id\"]=train_ts[\"id\"]\n",
    "test_ts_encoded['id']=test_ts[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed80a2c6",
   "metadata": {
    "papermill": {
     "duration": 0.024776,
     "end_time": "2024-12-18T23:59:19.481363",
     "exception": false,
     "start_time": "2024-12-18T23:59:19.456587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TABULAR NORMAL DATA PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f088122",
   "metadata": {
    "papermill": {
     "duration": 0.024603,
     "end_time": "2024-12-18T23:59:19.530968",
     "exception": false,
     "start_time": "2024-12-18T23:59:19.506365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Drop any samplers which only missed any values in PCIAT test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd17a0e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:19.581437Z",
     "iopub.status.busy": "2024-12-18T23:59:19.581187Z",
     "iopub.status.idle": "2024-12-18T23:59:19.645457Z",
     "shell.execute_reply": "2024-12-18T23:59:19.644508Z"
    },
    "papermill": {
     "duration": 0.091694,
     "end_time": "2024-12-18T23:59:19.647333",
     "exception": false,
     "start_time": "2024-12-18T23:59:19.555639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/child-mind-institute-problematic-internet-use/train.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/child-mind-institute-problematic-internet-use/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "875a0fdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:19.698121Z",
     "iopub.status.busy": "2024-12-18T23:59:19.697599Z",
     "iopub.status.idle": "2024-12-18T23:59:19.706125Z",
     "shell.execute_reply": "2024-12-18T23:59:19.705560Z"
    },
    "papermill": {
     "duration": 0.035517,
     "end_time": "2024-12-18T23:59:19.707835",
     "exception": false,
     "start_time": "2024-12-18T23:59:19.672318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_not_in_test = ['PCIAT-PCIAT_01', 'PCIAT-PCIAT_02', 'PCIAT-PCIAT_03', 'PCIAT-PCIAT_04', 'PCIAT-PCIAT_05', 'PCIAT-PCIAT_06', 'PCIAT-PCIAT_07', 'PCIAT-PCIAT_08', 'PCIAT-PCIAT_09', 'PCIAT-PCIAT_10', 'PCIAT-PCIAT_11', 'PCIAT-PCIAT_12', 'PCIAT-PCIAT_13', 'PCIAT-PCIAT_14', 'PCIAT-PCIAT_15', 'PCIAT-PCIAT_16', 'PCIAT-PCIAT_17', 'PCIAT-PCIAT_18', 'PCIAT-PCIAT_19', 'PCIAT-PCIAT_20', 'PCIAT-PCIAT_Total', 'PCIAT-Season', 'sii']\n",
    "train_data = train_data.dropna(subset=columns_not_in_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6ce51e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T07:14:27.674761Z",
     "iopub.status.busy": "2024-12-16T07:14:27.674415Z",
     "iopub.status.idle": "2024-12-16T07:14:27.678811Z",
     "shell.execute_reply": "2024-12-16T07:14:27.677871Z",
     "shell.execute_reply.started": "2024-12-16T07:14:27.674731Z"
    },
    "papermill": {
     "duration": 0.024775,
     "end_time": "2024-12-18T23:59:19.757474",
     "exception": false,
     "start_time": "2024-12-18T23:59:19.732699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Drop season data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b73ab08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:19.843124Z",
     "iopub.status.busy": "2024-12-18T23:59:19.842512Z",
     "iopub.status.idle": "2024-12-18T23:59:19.846927Z",
     "shell.execute_reply": "2024-12-18T23:59:19.846087Z"
    },
    "papermill": {
     "duration": 0.066749,
     "end_time": "2024-12-18T23:59:19.848546",
     "exception": false,
     "start_time": "2024-12-18T23:59:19.781797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_seasonal_columns = [col for col in train_data.columns if 'Season' in col]\n",
    "test_seasonal_columns = [col for col in test_data.columns if 'Season' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2978a270",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:19.898776Z",
     "iopub.status.busy": "2024-12-18T23:59:19.898550Z",
     "iopub.status.idle": "2024-12-18T23:59:19.903952Z",
     "shell.execute_reply": "2024-12-18T23:59:19.903270Z"
    },
    "papermill": {
     "duration": 0.032521,
     "end_time": "2024-12-18T23:59:19.905702",
     "exception": false,
     "start_time": "2024-12-18T23:59:19.873181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_wo_season = train_data.drop(train_seasonal_columns, axis = 1)\n",
    "test_data_wo_season = test_data.drop(test_seasonal_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca2583cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:20.005937Z",
     "iopub.status.busy": "2024-12-18T23:59:20.005699Z",
     "iopub.status.idle": "2024-12-18T23:59:20.011264Z",
     "shell.execute_reply": "2024-12-18T23:59:20.010534Z"
    },
    "papermill": {
     "duration": 0.032508,
     "end_time": "2024-12-18T23:59:20.012802",
     "exception": false,
     "start_time": "2024-12-18T23:59:19.980294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_related_features = ['PCIAT-PCIAT_01', 'PCIAT-PCIAT_02', 'PCIAT-PCIAT_03', 'PCIAT-PCIAT_04', 'PCIAT-PCIAT_05', 'PCIAT-PCIAT_06', 'PCIAT-PCIAT_07', 'PCIAT-PCIAT_08', 'PCIAT-PCIAT_09', 'PCIAT-PCIAT_10', 'PCIAT-PCIAT_11', 'PCIAT-PCIAT_12', 'PCIAT-PCIAT_13', 'PCIAT-PCIAT_14', 'PCIAT-PCIAT_15', 'PCIAT-PCIAT_16', 'PCIAT-PCIAT_17', 'PCIAT-PCIAT_18', 'PCIAT-PCIAT_19', 'PCIAT-PCIAT_20', 'PCIAT-PCIAT_Total', 'sii']\n",
    "label = ['PCIAT-PCIAT_Total']\n",
    "X = train_data_wo_season.drop(label_related_features, axis = 1)\n",
    "new_y = train_data_wo_season[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "425791af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:20.063321Z",
     "iopub.status.busy": "2024-12-18T23:59:20.063078Z",
     "iopub.status.idle": "2024-12-18T23:59:20.068007Z",
     "shell.execute_reply": "2024-12-18T23:59:20.067408Z"
    },
    "papermill": {
     "duration": 0.032138,
     "end_time": "2024-12-18T23:59:20.069514",
     "exception": false,
     "start_time": "2024-12-18T23:59:20.037376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_X = X.drop(['id'], axis = 1)\n",
    "new_test = test_data_wo_season.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2aad4d",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a248ad5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:20.119814Z",
     "iopub.status.busy": "2024-12-18T23:59:20.119591Z",
     "iopub.status.idle": "2024-12-18T23:59:20.126730Z",
     "shell.execute_reply": "2024-12-18T23:59:20.126085Z"
    },
    "papermill": {
     "duration": 0.03439,
     "end_time": "2024-12-18T23:59:20.128314",
     "exception": false,
     "start_time": "2024-12-18T23:59:20.093924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    #Age\n",
    "    df['Internet_Hours_Age'] = df['PreInt_EduHx-computerinternet_hoursday'] * df['Basic_Demos-Age']\n",
    "    df['Physical-Waist_Age'] = df['Basic_Demos-Age'] * df['Physical-Waist_Circumference']\n",
    "    df['BMI_Age'] = df['Physical-BMI'] * df['Basic_Demos-Age']\n",
    "    df['Physical-Height_Age'] = df['Basic_Demos-Age'] * df['Physical-Height']\n",
    "    df['SDS_InternetHours'] = df['SDS-SDS_Total_T'] * df['PreInt_EduHx-computerinternet_hoursday']\n",
    "\n",
    "    #SDS\n",
    "    df['SDS_BMI'] = df['BIA-BIA_BMI'] * df['SDS-SDS_Total_T']\n",
    "    df['CGAS_SDS'] = df['CGAS-CGAS_Score'] * df['SDS-SDS_Total_T']\n",
    "    df['CGAS_Endurance_Mins'] = df['CGAS-CGAS_Score'] * df['Fitness_Endurance-Time_Mins']\n",
    "    df['SDS_Activity'] = df['BIA-BIA_Activity_Level_num'] * df['SDS-SDS_Total_T']\n",
    "\n",
    "    df['BMI_Systolic_BP'] = df['BIA-BIA_BMI'] * df['Physical-Systolic_BP']\n",
    "    df['Age_Systolic_BP'] = df['Basic_Demos-Age'] * df['Physical-Systolic_BP']\n",
    "    df['PreInt_Systolic_BP'] = df['Physical-Systolic_BP'] * df['PreInt_EduHx-computerinternet_hoursday']\n",
    "    df['PAQ_A_Activity'] = df['BIA-BIA_Activity_Level_num'] * df['PAQ_A-PAQ_A_Total']\n",
    "    df['Activity_CU_PU'] = df['BIA-BIA_Activity_Level_num'] * df['FGC-FGC_CU'] * df['FGC-FGC_PU']\n",
    "\n",
    "    #FGC\n",
    "    df['FGC_CU_PU'] = df['FGC-FGC_CU'] * df['FGC-FGC_PU']\n",
    "    df['FGC_CU_PU_Age'] = df['FGC-FGC_CU'] * df['FGC-FGC_PU'] * df['Basic_Demos-Age']\n",
    "    df['FGC_GSND_GSD'] = df['FGC-FGC_GSND'] * df['FGC-FGC_GSD']\n",
    "    df['FGC_GSND_GSD_Age'] = df['FGC-FGC_GSND'] * df['FGC-FGC_GSD'] * df['Basic_Demos-Age']\n",
    "    df['CGAS_CU_PU'] = df['CGAS-CGAS_Score'] * df['FGC-FGC_CU'] * df['FGC-FGC_PU']\n",
    "    df['PreInt_FGC_CU_PU'] = df['PreInt_EduHx-computerinternet_hoursday'] * df['FGC-FGC_CU'] * df['FGC-FGC_PU']\n",
    "    df['Endurance_CU_PU'] = df['Fitness_Endurance-Time_Mins'] * df['FGC-FGC_CU'] * df['FGC-FGC_PU']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96981d64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:20.178683Z",
     "iopub.status.busy": "2024-12-18T23:59:20.178432Z",
     "iopub.status.idle": "2024-12-18T23:59:20.200917Z",
     "shell.execute_reply": "2024-12-18T23:59:20.200126Z"
    },
    "papermill": {
     "duration": 0.049595,
     "end_time": "2024-12-18T23:59:20.202602",
     "exception": false,
     "start_time": "2024-12-18T23:59:20.153007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_X = feature_engineering(new_X)\n",
    "new_test = feature_engineering(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4afd249b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:20.309612Z",
     "iopub.status.busy": "2024-12-18T23:59:20.309353Z",
     "iopub.status.idle": "2024-12-18T23:59:20.332454Z",
     "shell.execute_reply": "2024-12-18T23:59:20.331637Z"
    },
    "papermill": {
     "duration": 0.050563,
     "end_time": "2024-12-18T23:59:20.334176",
     "exception": false,
     "start_time": "2024-12-18T23:59:20.283613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/extmath.py:1047: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/extmath.py:1052: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/extmath.py:1072: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "new_X = pd.DataFrame(standard_scaler.fit_transform(new_X), columns=new_X.columns)\n",
    "new_test = pd.DataFrame(standard_scaler.fit_transform(new_test), columns=new_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561feda7",
   "metadata": {
    "papermill": {
     "duration": 0.025167,
     "end_time": "2024-12-18T23:59:20.384849",
     "exception": false,
     "start_time": "2024-12-18T23:59:20.359682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## IMPUTATION IN NORMAL TABULAR DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "363221b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:59:20.696489Z",
     "iopub.status.busy": "2024-12-18T23:59:20.696179Z",
     "iopub.status.idle": "2024-12-18T23:59:20.700938Z",
     "shell.execute_reply": "2024-12-18T23:59:20.700284Z"
    },
    "papermill": {
     "duration": 0.031971,
     "end_time": "2024-12-18T23:59:20.702417",
     "exception": false,
     "start_time": "2024-12-18T23:59:20.670446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_na_with_MICE(df):\n",
    "    df_copy = df.copy()\n",
    "    missing_mask = df_copy.isna()\n",
    "    original_columns = df_copy.columns.tolist()\n",
    "    imputer = IterativeImputer(max_iter=50, random_state=0)\n",
    "    imputed_values = imputer.fit_transform(df_copy)\n",
    "    imputed_df = pd.DataFrame(\n",
    "        imputed_values,\n",
    "        columns=original_columns,\n",
    "        index=df_copy.index\n",
    "    )\n",
    "    df_copy[missing_mask] = imputed_df[missing_mask]\n",
    "    return df_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0118c64",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## MERGE PARQUET INTO TABULAR DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039521a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:06.945839Z",
     "iopub.status.busy": "2024-12-18T23:41:06.945566Z",
     "iopub.status.idle": "2024-12-18T23:41:06.953231Z",
     "shell.execute_reply": "2024-12-18T23:41:06.952429Z",
     "shell.execute_reply.started": "2024-12-18T23:41:06.945812Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ts_encoded[\"id\"] = train_ts[\"id\"]\n",
    "new_X['id'] =  train_data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298b59e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:06.954598Z",
     "iopub.status.busy": "2024-12-18T23:41:06.954261Z",
     "iopub.status.idle": "2024-12-18T23:41:06.966098Z",
     "shell.execute_reply": "2024-12-18T23:41:06.965406Z",
     "shell.execute_reply.started": "2024-12-18T23:41:06.954556Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ts_encoded['id'] = test_ts['id']\n",
    "new_test['id'] = test_data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57634b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:06.967179Z",
     "iopub.status.busy": "2024-12-18T23:41:06.966937Z",
     "iopub.status.idle": "2024-12-18T23:41:06.989351Z",
     "shell.execute_reply": "2024-12-18T23:41:06.988674Z",
     "shell.execute_reply.started": "2024-12-18T23:41:06.967154Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_train = pd.merge(new_X, train_ts_encoded, how='left', on = 'id')\n",
    "merged_test = pd.merge(new_test, test_ts_encoded, how='left', on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c00b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:06.990580Z",
     "iopub.status.busy": "2024-12-18T23:41:06.990293Z",
     "iopub.status.idle": "2024-12-18T23:41:06.995256Z",
     "shell.execute_reply": "2024-12-18T23:41:06.994419Z",
     "shell.execute_reply.started": "2024-12-18T23:41:06.990555Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_train_not_fill = merged_train.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801fee3a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## AFTER MERGED, FILL NULL WITH MERGED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159019a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:06.996449Z",
     "iopub.status.busy": "2024-12-18T23:41:06.996202Z",
     "iopub.status.idle": "2024-12-18T23:41:07.006162Z",
     "shell.execute_reply": "2024-12-18T23:41:07.005523Z",
     "shell.execute_reply.started": "2024-12-18T23:41:06.996424Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_train_wo_id = merged_train.drop('id', axis = 1)\n",
    "merged_test_wo_id = merged_test.drop('id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9c3f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:07.007231Z",
     "iopub.status.busy": "2024-12-18T23:41:07.006991Z",
     "iopub.status.idle": "2024-12-18T23:41:07.028773Z",
     "shell.execute_reply": "2024-12-18T23:41:07.027980Z",
     "shell.execute_reply.started": "2024-12-18T23:41:07.007206Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "float64_cols = merged_train_wo_id.select_dtypes(include=['float64']).columns\n",
    "merged_train_wo_id[float64_cols] = merged_train_wo_id[float64_cols].astype('float32')\n",
    "merged_test_wo_id[float64_cols] = merged_test_wo_id[float64_cols].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4b6b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:07.045702Z",
     "iopub.status.busy": "2024-12-18T23:41:07.045399Z",
     "iopub.status.idle": "2024-12-18T23:41:09.474913Z",
     "shell.execute_reply": "2024-12-18T23:41:09.473971Z",
     "shell.execute_reply.started": "2024-12-18T23:41:07.045678Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=10)\n",
    "\n",
    "numeric_cols = merged_train_wo_id.select_dtypes(include=['float64', 'int64', 'float32']).columns\n",
    "print(numeric_cols)\n",
    "imputed_data = imputer.fit_transform(merged_train_wo_id[numeric_cols])\n",
    "\n",
    "train_imputed = pd.DataFrame(imputed_data, columns=numeric_cols)\n",
    "for col in merged_train_wo_id.columns:\n",
    "    if col not in numeric_cols:\n",
    "        train_imputed[col] = merged_train_wo_id[col]\n",
    "\n",
    "merged_train_wo_id = train_imputed\n",
    "\n",
    "imputed_data = imputer.fit_transform(merged_test_wo_id[numeric_cols])\n",
    "\n",
    "test_imputed = pd.DataFrame(imputed_data, columns=numeric_cols)\n",
    "for col in merged_test_wo_id.columns:\n",
    "    if col not in numeric_cols:\n",
    "        test_imputed[col] = merged_test_wo_id[col]\n",
    "\n",
    "merged_test_wo_id = test_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f2258",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:09.479346Z",
     "iopub.status.busy": "2024-12-18T23:41:09.479073Z",
     "iopub.status.idle": "2024-12-18T23:41:09.483250Z",
     "shell.execute_reply": "2024-12-18T23:41:09.482496Z",
     "shell.execute_reply.started": "2024-12-18T23:41:09.479321Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_X = merged_train_wo_id\n",
    "new_test = merged_test_wo_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3ba58",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3221530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:09.484575Z",
     "iopub.status.busy": "2024-12-18T23:41:09.484276Z",
     "iopub.status.idle": "2024-12-18T23:41:09.495208Z",
     "shell.execute_reply": "2024-12-18T23:41:09.494526Z",
     "shell.execute_reply.started": "2024-12-18T23:41:09.484549Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_info_for_ftt(df):\n",
    "    number_of_cat = 0\n",
    "    cat_ranges = []\n",
    "    all_features = df.columns.tolist()\n",
    "    cat_idx = []\n",
    "    for i, feature in enumerate(all_features):\n",
    "        if (df[feature].nunique() <= 2):\n",
    "            number_of_cat = number_of_cat + 1\n",
    "            cat_ranges.append(df[feature].nunique())\n",
    "            cat_idx.append(i)\n",
    "    \n",
    "    num_continuous = df.shape[-1] - number_of_cat\n",
    "    return cat_ranges, num_continuous, cat_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b1442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:09.496557Z",
     "iopub.status.busy": "2024-12-18T23:41:09.496233Z",
     "iopub.status.idle": "2024-12-18T23:41:09.505942Z",
     "shell.execute_reply": "2024-12-18T23:41:09.505140Z",
     "shell.execute_reply.started": "2024-12-18T23:41:09.496520Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, samples, labels, cat_idx):\n",
    "        if isinstance(labels, pd.DataFrame) or isinstance(labels, pd.Series):\n",
    "            labels = labels.to_numpy()\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "        self.cat_idx = cat_idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "    def divide_cat_num(self, row_data):\n",
    "        mask = np.zeros(len(row_data), dtype=bool)\n",
    "        mask[self.cat_idx] = True\n",
    "        cat_elements = row_data[mask]\n",
    "        remaining_elements = row_data[~mask]\n",
    "        return cat_elements, remaining_elements\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row_value = self.samples[idx]\n",
    "        tensor_row_value = torch.tensor(row_value)\n",
    "        cat_values, num_values = self.divide_cat_num(row_value)\n",
    "        cat_values = torch.tensor(cat_values, dtype=torch.int32)\n",
    "        num_values = torch.tensor(num_values, dtype=torch.float32)\n",
    "        label = self.labels[idx]\n",
    "        tensor_label = torch.tensor(label, dtype=torch.float32) \n",
    "        return cat_values, num_values, tensor_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30800e10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:09.506979Z",
     "iopub.status.busy": "2024-12-18T23:41:09.506694Z",
     "iopub.status.idle": "2024-12-18T23:41:09.518552Z",
     "shell.execute_reply": "2024-12-18T23:41:09.517796Z",
     "shell.execute_reply.started": "2024-12-18T23:41:09.506954Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eaf3ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:09.519689Z",
     "iopub.status.busy": "2024-12-18T23:41:09.519444Z",
     "iopub.status.idle": "2024-12-18T23:41:50.600587Z",
     "shell.execute_reply": "2024-12-18T23:41:50.599692Z",
     "shell.execute_reply.started": "2024-12-18T23:41:09.519654Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install /kaggle/input/fttransformer/einops-0.8.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd7ac4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:50.602172Z",
     "iopub.status.busy": "2024-12-18T23:41:50.601905Z",
     "iopub.status.idle": "2024-12-18T23:41:50.606445Z",
     "shell.execute_reply": "2024-12-18T23:41:50.605547Z",
     "shell.execute_reply.started": "2024-12-18T23:41:50.602146Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd4ca0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:50.607686Z",
     "iopub.status.busy": "2024-12-18T23:41:50.607445Z",
     "iopub.status.idle": "2024-12-18T23:41:50.638873Z",
     "shell.execute_reply": "2024-12-18T23:41:50.638290Z",
     "shell.execute_reply.started": "2024-12-18T23:41:50.607663Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_ranges, num_continuous, cat_idx = get_info_for_ftt(new_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5351be84",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Making wrapper for FTTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d974ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:50.639996Z",
     "iopub.status.busy": "2024-12-18T23:41:50.639793Z",
     "iopub.status.idle": "2024-12-18T23:41:50.667860Z",
     "shell.execute_reply": "2024-12-18T23:41:50.667166Z",
     "shell.execute_reply.started": "2024-12-18T23:41:50.639974Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, einsum\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "# feedforward and attention\n",
    "\n",
    "class GEGLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x, gates = x.chunk(2, dim = -1)\n",
    "        return x * F.gelu(gates)\n",
    "\n",
    "def FeedForward(dim, mult = 4, dropout = 0.):\n",
    "    return nn.Sequential(\n",
    "        nn.LayerNorm(dim),\n",
    "        nn.Linear(dim, dim * mult * 2),\n",
    "        GEGLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(dim * mult, dim)\n",
    "    )\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        heads = 8,\n",
    "        dim_head = 64,\n",
    "        dropout = 0.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        \n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim, bias = False)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.heads\n",
    "\n",
    "        x = self.norm(x)\n",
    "\n",
    "        q, k, v = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = einsum('b h i d, b h j d -> b h i j', q, k)\n",
    "\n",
    "        attn = sim.softmax(dim = -1)\n",
    "        dropped_attn = self.dropout(attn)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', dropped_attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)', h = h)\n",
    "        out = self.to_out(out)\n",
    "\n",
    "        return out, attn\n",
    "\n",
    "# transformer\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        depth,\n",
    "        heads,\n",
    "        dim_head,\n",
    "        attn_dropout,\n",
    "        ff_dropout\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads = heads, dim_head = dim_head, dropout = attn_dropout),\n",
    "                FeedForward(dim, dropout = ff_dropout),\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x, return_attn = False):\n",
    "        post_softmax_attns = []\n",
    "\n",
    "        for attn, ff in self.layers:\n",
    "            attn_out, post_softmax_attn = attn(x)\n",
    "            post_softmax_attns.append(post_softmax_attn)\n",
    "\n",
    "            x = attn_out + x\n",
    "            x = ff(x) + x\n",
    "\n",
    "        if not return_attn:\n",
    "            return x\n",
    "\n",
    "        return x, torch.stack(post_softmax_attns)\n",
    "        \n",
    "# batch norm\n",
    "class BatchNormSequence(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm1d(dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, sequence, features)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.bn(x)\n",
    "        x = x.transpose(1, 2) \n",
    "        return x\n",
    "        \n",
    "# numerical embedder\n",
    "class NumericalEmbedder(nn.Module):\n",
    "    def __init__(self, dim, num_numerical_types):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(num_numerical_types, dim))\n",
    "        self.biases = nn.Parameter(torch.randn(num_numerical_types, dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = rearrange(x, 'b n -> b n 1')\n",
    "        return x * self.weights + self.biases\n",
    "\n",
    "# main class\n",
    "\n",
    "class FTTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        categories,\n",
    "        num_continuous,\n",
    "        dim,\n",
    "        depth,\n",
    "        heads,\n",
    "        dim_head = 16,\n",
    "        dim_out = 1,\n",
    "        num_special_tokens = 2,\n",
    "        attn_dropout = 0.,\n",
    "        ff_dropout = 0.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert all(map(lambda n: n > 0, categories)), 'number of each category must be positive'\n",
    "        assert len(categories) + num_continuous > 0, 'input shape must not be null'\n",
    "\n",
    "       \n",
    "        self.num_categories = len(categories)\n",
    "        self.num_unique_categories = sum(categories)\n",
    "\n",
    "       \n",
    "\n",
    "        self.num_special_tokens = num_special_tokens\n",
    "        total_tokens = self.num_unique_categories + num_special_tokens\n",
    "\n",
    "        \n",
    "\n",
    "        if self.num_unique_categories > 0:\n",
    "            categories_offset = F.pad(torch.tensor(list(categories)), (1, 0), value = num_special_tokens)\n",
    "            categories_offset = categories_offset.cumsum(dim = -1)[:-1]\n",
    "            self.register_buffer('categories_offset', categories_offset)\n",
    "\n",
    "            \n",
    "\n",
    "            self.categorical_embeds = nn.Embedding(total_tokens, dim)\n",
    "            self.categ_bn = BatchNormSequence(dim)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        self.num_continuous = num_continuous\n",
    "\n",
    "        if self.num_continuous > 0:\n",
    "            self.numerical_embedder = NumericalEmbedder(dim, self.num_continuous)\n",
    "            self.numer_bn = BatchNormSequence(dim)\n",
    "\n",
    "\n",
    "        # cls token\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.pre_transformer_bn = BatchNormSequence(dim)\n",
    "\n",
    "        # transformer\n",
    "\n",
    "        self.transformer = Transformer(\n",
    "            dim = dim,\n",
    "            depth = depth,\n",
    "            heads = heads,\n",
    "            dim_head = dim_head,\n",
    "            attn_dropout = attn_dropout,\n",
    "            ff_dropout = ff_dropout\n",
    "        )\n",
    "\n",
    "        # to logits\n",
    "\n",
    "        self.to_logits = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim, dim_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_categ, x_numer, return_attn = False):\n",
    "        assert x_categ.shape[-1] == self.num_categories, f'you must pass in {self.num_categories} values for your categories input'\n",
    "\n",
    "        xs = []\n",
    "        if self.num_unique_categories > 0:\n",
    "            x_categ = x_categ + self.categories_offset\n",
    "\n",
    "            x_categ = self.categorical_embeds(x_categ)\n",
    "            x_categ = self.categ_bn(x_categ)\n",
    "            xs.append(x_categ)\n",
    "\n",
    "        # add numerically embedded tokens\n",
    "        if self.num_continuous > 0:\n",
    "            x_numer = self.numerical_embedder(x_numer)\n",
    "            x_numer = self.numer_bn(x_numer)\n",
    "            xs.append(x_numer)\n",
    "\n",
    "        # concat categorical and numerical\n",
    "\n",
    "        x = torch.cat(xs, dim = 1)\n",
    "        x = self.pre_transformer_bn(x)\n",
    "\n",
    "\n",
    "        # append cls tokens\n",
    "        b = x.shape[0]\n",
    "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim = 1)\n",
    "        \n",
    "        # attend\n",
    "\n",
    "        x, attns = self.transformer(x, return_attn = True)\n",
    "\n",
    "        # get cls token\n",
    "\n",
    "        x = x[:, 0]\n",
    "\n",
    "        \n",
    "\n",
    "        logits = self.to_logits(x)\n",
    "\n",
    "        if not return_attn:\n",
    "            return logits\n",
    "\n",
    "        return logits, attns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c61643e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:50.668946Z",
     "iopub.status.busy": "2024-12-18T23:41:50.668677Z",
     "iopub.status.idle": "2024-12-18T23:41:50.681179Z",
     "shell.execute_reply": "2024-12-18T23:41:50.680512Z",
     "shell.execute_reply.started": "2024-12-18T23:41:50.668922Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249d778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:50.682421Z",
     "iopub.status.busy": "2024-12-18T23:41:50.682109Z",
     "iopub.status.idle": "2024-12-18T23:41:50.695038Z",
     "shell.execute_reply": "2024-12-18T23:41:50.694461Z",
     "shell.execute_reply.started": "2024-12-18T23:41:50.682384Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def qwk(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2bfede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:50.696280Z",
     "iopub.status.busy": "2024-12-18T23:41:50.696012Z",
     "iopub.status.idle": "2024-12-18T23:41:50.720315Z",
     "shell.execute_reply": "2024-12-18T23:41:50.719663Z",
     "shell.execute_reply.started": "2024-12-18T23:41:50.696255Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FTTransformerWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, categories, num_continuous, dim, dim_out, depth, heads, attn_dropout, \n",
    "                 ff_dropout, batch_size, num_epochs, learning_rate, cat_ranges, cat_idx):\n",
    "        self.categories = categories\n",
    "        self.num_continuous = num_continuous\n",
    "        self.dim = dim\n",
    "        self.dim_out = dim_out\n",
    "        self.depth = depth\n",
    "        self.heads = heads\n",
    "        self.attn_dropout = attn_dropout\n",
    "        self.ff_dropout = ff_dropout\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.cat_ranges = cat_ranges\n",
    "        self.cat_idx = cat_idx\n",
    "        self.num_epochs = num_epochs\n",
    "        \n",
    "    def _init_model(self):\n",
    "        self.model = FTTransformer(\n",
    "            categories=self.categories,\n",
    "            num_continuous=self.num_continuous,\n",
    "            dim=self.dim,\n",
    "            dim_out=self.dim_out,\n",
    "            depth=self.depth,\n",
    "            heads=self.heads,\n",
    "            attn_dropout=self.attn_dropout,\n",
    "            ff_dropout=self.ff_dropout\n",
    "        ).to(self.device)\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        print(\"--------------------------------type of X_train\", type(X_train))\n",
    "        print(\"---------------------------------------shape of X\", X_train.shape)\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        self.scaler = StandardScaler()\n",
    "        scaled_X_train = self.scaler.fit_transform(X_train)\n",
    "        scaled_X_val = self.scaler.transform(X_val)\n",
    "        \n",
    "        train_dataset = MyDataset(scaled_X_train, y_train, self.cat_idx)\n",
    "        val_dataset = MyDataset(scaled_X_val, y_val, self.cat_idx)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "        self._init_model()\n",
    "        best_val_loss = float('inf')\n",
    "\n",
    "        save_path='model_checkpoints'\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            for x_cat, x_num, y in train_loader:\n",
    "                x_cat = x_cat.to(self.device) if x_cat is not None else None\n",
    "                x_num = x_num.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(x_cat, x_num).squeeze(1)\n",
    "                \n",
    "                loss = self.criterion(output, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            self.model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for x_cat, x_num, y in val_loader:\n",
    "                    x_cat = x_cat.to(self.device) if x_cat is not None else None\n",
    "                    x_num = x_num.to(self.device)\n",
    "                    y = y.to(self.device)\n",
    "                    \n",
    "                    output = self.model(x_cat, x_num).squeeze(1)\n",
    "\n",
    "                    val_loss += self.criterion(output, y).item()\n",
    "\n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'best_val_loss': best_val_loss\n",
    "                }\n",
    "                torch.save(checkpoint, os.path.join(save_path, f'best_model.pth'))\n",
    "                print(f'Saved best model with validation loss: {best_val_loss:.4f}')\n",
    "\n",
    "    def load_model(self, model, checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        return model\n",
    "\n",
    "    def load_model_checkpoint(self, checkpoint_path):\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            self.model.to(self.device)\n",
    "            self.model.eval()\n",
    "            print(f\"Model loaded from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading the model: {e}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.model = self.load_model(self.model, \"/kaggle/working/model_checkpoints/best_model.pth\")\n",
    "\n",
    "        def divide_cat_num(data, cat_idx):\n",
    "            mask = np.zeros(data.shape[1], dtype=bool)\n",
    "            mask[cat_idx] = True\n",
    "            cat_elements = data[:, mask]\n",
    "            remaining_elements = data[:, ~mask]\n",
    "            return cat_elements, remaining_elements\n",
    "\n",
    "        self.model.eval()\n",
    "        new_test_values = X.values\n",
    "        new_test_values = self.scaler.transform(new_test_values)\n",
    "        num_samples = len(new_test_values)\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(0, num_samples, self.batch_size):\n",
    "            batch_data = new_test_values[i:i + self.batch_size]\n",
    "            cat, num = divide_cat_num(batch_data, self.cat_idx)\n",
    "            cat = torch.tensor(cat, dtype=torch.int32).to(self.device)\n",
    "            num = torch.tensor(num, dtype=torch.float32).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = self.model(cat, num)\n",
    "                output = output.squeeze(1)\n",
    "                predictions.extend(output.cpu().numpy())\n",
    "\n",
    "            del cat\n",
    "            del num\n",
    "            del output\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            for x_cat, x_num, y in train_loader:\n",
    "                x_cat = x_cat.to(self.device) if x_cat is not None else None\n",
    "                x_num = x_num.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(x_cat, x_num).squeeze(1)\n",
    "                \n",
    "                loss = self.criterion(output, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            self.model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for x_cat, x_num, y in val_loader:\n",
    "                    x_cat = x_cat.to(self.device) if x_cat is not None else None\n",
    "                    x_num = x_num.to(self.device)\n",
    "                    y = y.to(self.device)\n",
    "                    \n",
    "                    output = self.model(x_cat, x_num).squeeze(1)\n",
    "\n",
    "                    val_loss += self.criterion(output, y).item()\n",
    "\n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'best_val_loss': best_val_loss\n",
    "                }\n",
    "                torch.save(checkpoint, os.path.join(save_path, f'best_model.pth'))\n",
    "                print(f'Saved best model with validation loss: {best_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bca8c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## QWK THRESHOLD OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64196997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:41:50.759908Z",
     "iopub.status.busy": "2024-12-18T23:41:50.759617Z",
     "iopub.status.idle": "2024-12-18T23:41:50.767392Z",
     "shell.execute_reply": "2024-12-18T23:41:50.766792Z",
     "shell.execute_reply.started": "2024-12-18T23:41:50.759884Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b319fb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1137.0349, Val Loss: 1061.5314\n",
      "Saved best model with validation loss: 1061.5314\n",
      "Epoch 2, Train Loss: 1100.1245, Val Loss: 1033.1532\n",
      "Saved best model with validation loss: 1033.1532\n",
      "Epoch 3, Train Loss: 1065.5473, Val Loss: 994.4426\n",
      "Saved best model with validation loss: 994.4426\n",
      "Epoch 4, Train Loss: 1027.9088, Val Loss: 950.4918\n",
      "Saved best model with validation loss: 950.4918\n",
      "Epoch 5, Train Loss: 981.9695, Val Loss: 907.5274\n",
      "Saved best model with validation loss: 907.5274\n",
      "Epoch 6, Train Loss: 931.1604, Val Loss: 859.9179\n",
      "Saved best model with validation loss: 859.9179\n",
      "Epoch 7, Train Loss: 880.3323, Val Loss: 800.4043\n",
      "Saved best model with validation loss: 800.4043\n",
      "Epoch 8, Train Loss: 829.5012, Val Loss: 758.3185\n",
      "Saved best model with validation loss: 758.3185\n",
      "Epoch 9, Train Loss: 775.5452, Val Loss: 714.2839\n",
      "Saved best model with validation loss: 714.2839\n",
      "Epoch 10, Train Loss: 724.2818, Val Loss: 665.0346\n",
      "Saved best model with validation loss: 665.0346\n",
      "Epoch 11, Train Loss: 674.4083, Val Loss: 615.5845\n",
      "Saved best model with validation loss: 615.5845\n",
      "Epoch 12, Train Loss: 630.9794, Val Loss: 576.7512\n",
      "Saved best model with validation loss: 576.7512\n",
      "Epoch 13, Train Loss: 589.8333, Val Loss: 538.8756\n",
      "Saved best model with validation loss: 538.8756\n",
      "Epoch 14, Train Loss: 553.5820, Val Loss: 512.3714\n",
      "Saved best model with validation loss: 512.3714\n",
      "Epoch 15, Train Loss: 523.1120, Val Loss: 487.3087\n",
      "Saved best model with validation loss: 487.3087\n",
      "Epoch 16, Train Loss: 496.7047, Val Loss: 462.2316\n",
      "Saved best model with validation loss: 462.2316\n",
      "Epoch 17, Train Loss: 475.6053, Val Loss: 451.5776\n",
      "Saved best model with validation loss: 451.5776\n",
      "Epoch 18, Train Loss: 457.1064, Val Loss: 435.4733\n",
      "Saved best model with validation loss: 435.4733\n",
      "Epoch 19, Train Loss: 444.6219, Val Loss: 425.6083\n",
      "Saved best model with validation loss: 425.6083\n",
      "Epoch 20, Train Loss: 433.9993, Val Loss: 419.0074\n",
      "Saved best model with validation loss: 419.0074\n",
      "Epoch 21, Train Loss: 420.8852, Val Loss: 392.2435\n",
      "Saved best model with validation loss: 392.2435\n",
      "Epoch 22, Train Loss: 396.1338, Val Loss: 379.7688\n",
      "Saved best model with validation loss: 379.7688\n",
      "Epoch 23, Train Loss: 380.3033, Val Loss: 365.4826\n",
      "Saved best model with validation loss: 365.4826\n",
      "Epoch 24, Train Loss: 365.3248, Val Loss: 358.4361\n",
      "Saved best model with validation loss: 358.4361\n",
      "Epoch 25, Train Loss: 353.8867, Val Loss: 343.5566\n",
      "Saved best model with validation loss: 343.5566\n",
      "Epoch 26, Train Loss: 344.0698, Val Loss: 338.2799\n",
      "Saved best model with validation loss: 338.2799\n",
      "Epoch 27, Train Loss: 333.9884, Val Loss: 334.4303\n",
      "Saved best model with validation loss: 334.4303\n",
      "Epoch 28, Train Loss: 330.1313, Val Loss: 328.7691\n",
      "Saved best model with validation loss: 328.7691\n",
      "Epoch 29, Train Loss: 322.4863, Val Loss: 324.6045\n",
      "Saved best model with validation loss: 324.6045\n",
      "Epoch 30, Train Loss: 318.3240, Val Loss: 315.9028\n",
      "Saved best model with validation loss: 315.9028\n",
      "Epoch 31, Train Loss: 313.5750, Val Loss: 324.0671\n",
      "Epoch 32, Train Loss: 312.7291, Val Loss: 315.0692\n",
      "Saved best model with validation loss: 315.0692\n",
      "Epoch 33, Train Loss: 307.0423, Val Loss: 307.2938\n",
      "Saved best model with validation loss: 307.2938\n",
      "Epoch 34, Train Loss: 304.7484, Val Loss: 307.6766\n",
      "Epoch 35, Train Loss: 300.7475, Val Loss: 306.1252\n",
      "Saved best model with validation loss: 306.1252\n",
      "Epoch 36, Train Loss: 298.9047, Val Loss: 303.3913\n",
      "Saved best model with validation loss: 303.3913\n",
      "Epoch 37, Train Loss: 297.7570, Val Loss: 301.9162\n",
      "Saved best model with validation loss: 301.9162\n",
      "Epoch 38, Train Loss: 296.7075, Val Loss: 297.2313\n",
      "Saved best model with validation loss: 297.2313\n",
      "Epoch 39, Train Loss: 293.5016, Val Loss: 296.6608\n",
      "Saved best model with validation loss: 296.6608\n",
      "Epoch 40, Train Loss: 292.2392, Val Loss: 306.4283\n",
      "Epoch 41, Train Loss: 290.6911, Val Loss: 295.5614\n",
      "Saved best model with validation loss: 295.5614\n",
      "Epoch 42, Train Loss: 286.1191, Val Loss: 293.8804\n",
      "Saved best model with validation loss: 293.8804\n",
      "Epoch 43, Train Loss: 288.3867, Val Loss: 295.3734\n",
      "Epoch 44, Train Loss: 285.8618, Val Loss: 295.2040\n",
      "Epoch 45, Train Loss: 286.8571, Val Loss: 297.5579\n",
      "Epoch 46, Train Loss: 284.7876, Val Loss: 296.2069\n",
      "Epoch 47, Train Loss: 281.0527, Val Loss: 293.4282\n",
      "Saved best model with validation loss: 293.4282\n",
      "Epoch 48, Train Loss: 285.9794, Val Loss: 292.9376\n",
      "Saved best model with validation loss: 292.9376\n",
      "Epoch 49, Train Loss: 280.1725, Val Loss: 289.8888\n",
      "Saved best model with validation loss: 289.8888\n",
      "Epoch 50, Train Loss: 280.3859, Val Loss: 291.9187\n",
      "Epoch 51, Train Loss: 280.2618, Val Loss: 293.0131\n",
      "Epoch 52, Train Loss: 278.6371, Val Loss: 299.9912\n",
      "Epoch 53, Train Loss: 280.7024, Val Loss: 297.3113\n",
      "Epoch 54, Train Loss: 280.8799, Val Loss: 290.8804\n",
      "Epoch 55, Train Loss: 278.0345, Val Loss: 291.9605\n",
      "Epoch 56, Train Loss: 274.4744, Val Loss: 297.1527\n",
      "Epoch 57, Train Loss: 275.6104, Val Loss: 297.2179\n",
      "Epoch 58, Train Loss: 271.2986, Val Loss: 292.8027\n",
      "Epoch 59, Train Loss: 275.4048, Val Loss: 292.7578\n",
      "Epoch 60, Train Loss: 275.3748, Val Loss: 295.0251\n",
      "Epoch 61, Train Loss: 274.4009, Val Loss: 294.7802\n",
      "Epoch 62, Train Loss: 270.7601, Val Loss: 298.0074\n",
      "Epoch 63, Train Loss: 272.6800, Val Loss: 295.3905\n",
      "Epoch 64, Train Loss: 275.2633, Val Loss: 292.4307\n",
      "Epoch 65, Train Loss: 272.9834, Val Loss: 293.7764\n",
      "Epoch 66, Train Loss: 272.3885, Val Loss: 291.7996\n",
      "Epoch 67, Train Loss: 274.7109, Val Loss: 297.5041\n",
      "Epoch 68, Train Loss: 272.8204, Val Loss: 293.0486\n",
      "Epoch 69, Train Loss: 275.9464, Val Loss: 292.2586\n",
      "Epoch 70, Train Loss: 268.0425, Val Loss: 295.0777\n",
      "Epoch 71, Train Loss: 268.1452, Val Loss: 292.2116\n",
      "Epoch 72, Train Loss: 275.4702, Val Loss: 291.6019\n",
      "Epoch 73, Train Loss: 265.3249, Val Loss: 290.1875\n",
      "Epoch 74, Train Loss: 268.0417, Val Loss: 297.5005\n",
      "Epoch 75, Train Loss: 266.9532, Val Loss: 293.0115\n",
      "Epoch 76, Train Loss: 265.8635, Val Loss: 296.8910\n",
      "Epoch 77, Train Loss: 261.6961, Val Loss: 297.0923\n",
      "Epoch 78, Train Loss: 267.3000, Val Loss: 300.7215\n",
      "Epoch 79, Train Loss: 264.6531, Val Loss: 304.0216\n",
      "Epoch 80, Train Loss: 263.5809, Val Loss: 298.8029\n",
      "Epoch 81, Train Loss: 263.9616, Val Loss: 297.7999\n",
      "Epoch 82, Train Loss: 265.2589, Val Loss: 294.2986\n",
      "Epoch 83, Train Loss: 263.3080, Val Loss: 306.6764\n",
      "Epoch 84, Train Loss: 260.0968, Val Loss: 296.4355\n",
      "Epoch 85, Train Loss: 262.7474, Val Loss: 300.0403\n",
      "Epoch 86, Train Loss: 262.8238, Val Loss: 299.5867\n",
      "Epoch 87, Train Loss: 257.4531, Val Loss: 300.0691\n",
      "Epoch 88, Train Loss: 261.9003, Val Loss: 303.6259\n",
      "Epoch 89, Train Loss: 260.1682, Val Loss: 305.8706\n",
      "Epoch 90, Train Loss: 257.2331, Val Loss: 297.1667\n",
      "Epoch 91, Train Loss: 260.8140, Val Loss: 297.2932\n",
      "Epoch 92, Train Loss: 257.6727, Val Loss: 297.9965\n",
      "Epoch 93, Train Loss: 257.1831, Val Loss: 299.1123\n",
      "Epoch 94, Train Loss: 257.8615, Val Loss: 298.4700\n",
      "Epoch 95, Train Loss: 257.1161, Val Loss: 301.3009\n",
      "Epoch 96, Train Loss: 254.4152, Val Loss: 300.3963\n",
      "Epoch 97, Train Loss: 258.0768, Val Loss: 296.9407\n",
      "Epoch 98, Train Loss: 253.4299, Val Loss: 299.1432\n",
      "Epoch 99, Train Loss: 252.6183, Val Loss: 300.1443\n",
      "Epoch 100, Train Loss: 258.7874, Val Loss: 309.7742\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    'categories': tuple(cat_ranges), \n",
    "    'num_continuous': num_continuous,    \n",
    "    'dim': 10,             \n",
    "    'dim_out': 1,          \n",
    "    'depth': 2,            \n",
    "    'heads': 3,            \n",
    "    'attn_dropout': 0.1,   \n",
    "    'ff_dropout': 0.1,\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 1e-3,\n",
    "    'cat_ranges': cat_ranges,\n",
    "    'cat_idx': cat_idx \n",
    "}\n",
    "model = FTTransformerWrapper(**model_params)\n",
    "model.fit(new_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c4b16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1148266811.py:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf1e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from /kaggle/working/model_checkpoints/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1148266811.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=self.device)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"/kaggle/working/model_checkpoints/best_model.pth\"\n",
    "# checkpoint_path = \"/kaggle/input/best_v1/pytorch/default/1/best_model_val_loss_291.7448.pth\"\n",
    "model.load_model_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87889db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(new_test, cat_idx, model, batch_size=16, track_memory=False):\n",
    "    def divide_cat_num(data, cat_idx):\n",
    "        mask = np.zeros(data.shape[1], dtype=bool)\n",
    "        mask[cat_idx] = True\n",
    "        cat_elements = data[:, mask]\n",
    "        remaining_elements = data[:, ~mask]\n",
    "        return cat_elements, remaining_elements\n",
    "    \n",
    "    device = 'cuda'\n",
    "    new_test_values = new_test.values\n",
    "    num_samples = len(new_test_values)\n",
    "    predictions = []\n",
    "\n",
    "    \n",
    "    # Process data in batches\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        if track_memory:\n",
    "            print(f'GPU Memory before batch {i}: {torch.cuda.memory_allocated()/1024**2:.2f} MB')\n",
    "            \n",
    "        batch_data = new_test_values[i:i + batch_size]\n",
    "        cat, num = divide_cat_num(batch_data, cat_idx)\n",
    "        \n",
    "        cat = torch.tensor(cat, dtype=torch.int32).to(device)\n",
    "        num = torch.tensor(num, dtype=torch.float32).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model.model(cat, num)\n",
    "            output = output.squeeze(1)\n",
    "            predictions.extend(output.cpu().numpy())\n",
    "        \n",
    "        # Clear GPU memory\n",
    "        del cat\n",
    "        del num\n",
    "        del output\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if track_memory:\n",
    "            print(f'GPU Memory after batch {i}: {torch.cuda.memory_allocated()/1024**2:.2f} MB')\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca096069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19.95567,\n",
       " 15.092413,\n",
       " 42.51784,\n",
       " 18.462057,\n",
       " 27.865429,\n",
       " 27.32825,\n",
       " 23.246046,\n",
       " 24.63583,\n",
       " 33.182278,\n",
       " 26.369068,\n",
       " 35.208183,\n",
       " 22.191006,\n",
       " 36.317226,\n",
       " 42.061874,\n",
       " 31.93947,\n",
       " 28.113201,\n",
       " 10.839161,\n",
       " 14.951689,\n",
       " 26.358326,\n",
       " 35.54263]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = get_prediction(new_test, cat_idx, model)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9994246",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec5ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_prediction(predictions, test_id):\n",
    "    # return submission.csv\n",
    "    sii = []\n",
    "    for i in range(len(predictions)):\n",
    "        predict = predictions[i]\n",
    "        if (predict >=  0 and predict <= 30):\n",
    "            sii.append(0)\n",
    "        elif(predict < 50):\n",
    "            sii.append(1)\n",
    "        elif(predict < 80):\n",
    "            sii.append(2)\n",
    "        else:\n",
    "            sii.append(3)\n",
    "    sii = pd.DataFrame(sii)\n",
    "    submission = pd.concat([test_id, sii], axis = 1)\n",
    "    submission = submission.rename(columns={0: 'sii'})\n",
    "    return submission\n",
    "submission = handle_prediction(prediction, test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044f7263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0038ba98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0068a485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0069fbed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0083e397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0087dd65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00abe655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae59c9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00af6387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00bd4359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00c0cd71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00d56d4b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00d9913d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00e6167c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00ebc35d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sii\n",
       "0   00008ff9    0\n",
       "1   000fd460    0\n",
       "2   00105258    1\n",
       "3   00115b9f    0\n",
       "4   0016bb22    0\n",
       "5   001f3379    0\n",
       "6   0038ba98    0\n",
       "7   0068a485    0\n",
       "8   0069fbed    1\n",
       "9   0083e397    0\n",
       "10  0087dd65    1\n",
       "11  00abe655    0\n",
       "12  00ae59c9    1\n",
       "13  00af6387    1\n",
       "14  00bd4359    1\n",
       "15  00c0cd71    0\n",
       "16  00d56d4b    0\n",
       "17  00d9913d    0\n",
       "18  00e6167c    0\n",
       "19  00ebc35d    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    },
    {
     "datasetId": 6261488,
     "sourceId": 10144188,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6274967,
     "sourceId": 10161833,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6303553,
     "sourceId": 10200802,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6305398,
     "sourceId": 10203245,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6308872,
     "sourceId": 10208164,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 191870,
     "modelInstanceId": 169524,
     "sourceId": 198747,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 136.203858,
   "end_time": "2024-12-19T00:00:06.320177",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-18T23:57:50.116319",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
